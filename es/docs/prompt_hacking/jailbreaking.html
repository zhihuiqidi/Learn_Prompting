<!doctype html>
<html lang="es" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-prompt_hacking/jailbreaking">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.3.1">
<title data-rh="true">🟢 Jailbreaking | 智慧启迪</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://zhihuiqidi.com/es/docs/prompt_hacking/jailbreaking"><meta data-rh="true" name="docusaurus_locale" content="es"><meta data-rh="true" name="docsearch:language" content="es"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="🟢 Jailbreaking | 智慧启迪"><meta data-rh="true" name="description" content="El Jailbreaking es un tipo de inyección de prompt, en la cual los prompts intentan pasar por alto las características de seguridad y moderación colocadas en los LLM por sus creadores (@perez2022jailbreak) (@brundage_2022) (@wang2022jailbreak)."><meta data-rh="true" property="og:description" content="El Jailbreaking es un tipo de inyección de prompt, en la cual los prompts intentan pasar por alto las características de seguridad y moderación colocadas en los LLM por sus creadores (@perez2022jailbreak) (@brundage_2022) (@wang2022jailbreak)."><link data-rh="true" rel="icon" href="/es/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://zhihuiqidi.com/es/docs/prompt_hacking/jailbreaking"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/en/docs/prompt_hacking/jailbreaking" hreflang="en"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/es/docs/prompt_hacking/jailbreaking" hreflang="es"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/fr/docs/prompt_hacking/jailbreaking" hreflang="fr"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/ja/docs/prompt_hacking/jailbreaking" hreflang="ja"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/pt/docs/prompt_hacking/jailbreaking" hreflang="pt"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/docs/prompt_hacking/jailbreaking" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/ko/docs/prompt_hacking/jailbreaking" hreflang="ko"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/si/docs/prompt_hacking/jailbreaking" hreflang="si"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/ru/docs/prompt_hacking/jailbreaking" hreflang="ru"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/docs/prompt_hacking/jailbreaking" hreflang="x-default"><link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-FV0C417KS8","auto"),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FV0C417KS8"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-FV0C417KS8",{})</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous">
<link rel="stylesheet" href="https://embed.trydyno.com/embedder.css" crossorigin="anonymous">
<script src="https://embed.trydyno.com/embedder.js" defer="defer"></script><link rel="stylesheet" href="/es/assets/css/styles.5962e7b7.css">
<link rel="preload" href="/es/assets/js/runtime~main.fb7f4835.js" as="script">
<link rel="preload" href="/es/assets/js/main.38ad3503.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Saltar al contenido principal"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Saltar al contenido principal</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/es/"><div class="navbar__logo"><img src="/es/img/simple_ai.png" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/es/img/simple_ai.png" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">智慧启迪</b></a><a class="navbar__item navbar__link" href="/es/docs/intro">Learn</a><a class="navbar__item navbar__link" href="/es/contribute">Contribute</a><a class="navbar__item navbar__link" href="/es/supporters">Supporters</a><a class="navbar__item navbar__link" href="/es/certificate">Certificate</a><a class="navbar__item navbar__link consulting-gradient" href="/es/consulting">Consulting</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>Español</a><ul class="dropdown__menu"><li><a href="/en/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/es/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="es">Español</a></li><li><a href="/fr/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="fr">Français</a></li><li><a href="/ja/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/pt/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-Hans">简体中文</a></li><li><a href="/ko/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/si/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="si">සිංහල</a></li><li><a href="/ru/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ru">Русский</a></li></ul></div><a href="https://github.com/trigaten/Learn_Prompting/releases" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Change Log<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://github.com/trigaten/promptgineering" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button class="flex items-center space-x-4 border px-2 py-1 rounded-full border-gray-300 hover:border-gray-400 focus:outline-none focus:ring-2 focus:ring-gray-400 focus:ring-opacity-50"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z"></path></svg><span class="hidden lg:block text-sm">Search</span><kbd class="hidden lg:inline-flex items-center rounded-xl border border-gray-200 px-2 font-sans text-sm font-medium text-gray-400">⌘K</kbd></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Volver al principio" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/es/docs/intro">Bienvenidos</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/es/docs/category/-basics">😃 Basics</a><button aria-label="Toggle the collapsible sidebar category &#x27;😃 Basics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/es/docs/category/-basic-applications">💼 Basic Applications</a><button aria-label="Toggle the collapsible sidebar category &#x27;💼 Basic Applications&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/es/docs/category/️-intermediate">🧙‍♂️ Intermediate</a><button aria-label="Toggle the collapsible sidebar category &#x27;🧙‍♂️ Intermediate&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/es/docs/category/-applied-prompting">🧪 Applied Prompting</a><button aria-label="Toggle the collapsible sidebar category &#x27;🧪 Applied Prompting&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/es/docs/category/-advanced-applications">🚀 Advanced Applications</a><button aria-label="Toggle the collapsible sidebar category &#x27;🚀 Advanced Applications&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/es/docs/category/️-reliability">⚖️ Reliability</a><button aria-label="Toggle the collapsible sidebar category &#x27;⚖️ Reliability&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/es/docs/category/️-image-prompting">🖼️ Image Prompting</a><button aria-label="Toggle the collapsible sidebar category &#x27;🖼️ Image Prompting&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/es/docs/category/-prompt-hacking">🔓 Prompt Hacking</a><button aria-label="Toggle the collapsible sidebar category &#x27;🔓 Prompt Hacking&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/prompt_hacking/injection">🟢 Inyección de Prompt</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/prompt_hacking/leaking">🟢 Fuga de Prompt</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/es/docs/prompt_hacking/jailbreaking">🟢 Jailbreaking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/prompt_hacking/defensive_measures">🟢 Medidas defensivas</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/es/docs/category/-tooling">🔨 Tooling</a><button aria-label="Toggle the collapsible sidebar category &#x27;🔨 Tooling&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/es/docs/category/-prompt-tuning">💪 Prompt Tuning</a><button aria-label="Toggle the collapsible sidebar category &#x27;💪 Prompt Tuning&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/es/docs/category/-miscellaneous">🎲 Miscellaneous</a><button aria-label="Toggle the collapsible sidebar category &#x27;🎲 Miscellaneous&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/es/docs/vocabulary">📙 Referencia de Vocabulario</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/es/docs/bibliography">📚 Bibliography</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/es/docs/products">📦 Prompted Products</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/es/docs/additional">🛸 Recursos adicionales</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/es/docs/credits">✨ Créditos</a></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/es/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/es/docs/category/-prompt-hacking"><span itemprop="name">🔓 Prompt Hacking</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">🟢 Jailbreaking</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">En esta página</button></div><div class="theme-doc-markdown markdown"><h1>🟢 Jailbreaking</h1><p>El Jailbreaking es un tipo de inyección de prompt, en la cual los prompts intentan pasar por alto las características de <strong>seguridad</strong> y <strong>moderación</strong> colocadas en los LLM por sus creadores<sup id="fnref-1"><a href="#fn-1" class="footnote-ref">1</a></sup><sup id="fnref-2"><a href="#fn-2" class="footnote-ref">2</a></sup><sup id="fnref-3"><a href="#fn-3" class="footnote-ref">3</a></sup>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="metodologías-de-jailbreaking">Metodologías de Jailbreaking<a href="#metodologías-de-jailbreaking" class="hash-link" aria-label="Enlace directo al Metodologías de Jailbreaking" title="Enlace directo al Metodologías de Jailbreaking">​</a></h2><p>OpenAI, entre otras empresas y organizaciones que crean LLMs, incluye características de moderación de contenido para asegurarse de que sus modelos no produzcan respuestas controvertidas (violentas, sexuales, ilegales, etc.)<sup id="fnref-4"><a href="#fn-4" class="footnote-ref">4</a></sup><sup id="fnref-5"><a href="#fn-5" class="footnote-ref">5</a></sup>. Esta página discute los jailbreaks con ChatGPT (un modelo de OpenAI), que tiene dificultades conocidas para decidir si rechazar o no los prompts dañinos<sup id="fnref-6"><a href="#fn-6" class="footnote-ref">6</a></sup>. Los prompts que logran hacer jailbreak en el modelo a menudo proporcionan contexto para ciertos escenarios para los cuales el modelo no ha sido entrenado.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="pretender">Pretender<a href="#pretender" class="hash-link" aria-label="Enlace directo al Pretender" title="Enlace directo al Pretender">​</a></h3><p>Un método común de jailbreaking es <em>pretender</em>. Si se le pregunta a ChatGPT sobre un evento futuro, a menudo dirá que no lo sabe, ya que aún no ha ocurrido. El siguiente prompt lo obliga a dar una respuesta posible:</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="pretender-simple">Pretender Simple<a href="#pretender-simple" class="hash-link" aria-label="Enlace directo al Pretender Simple" title="Enlace directo al Pretender Simple">​</a></h4><div style="text-align:center"><img loading="lazy" src="/es/assets/images/pretend_jailbreak-1f3664b88b0ef895981da40eca27e22a.png" style="width:500px" class="img_ev3q"></div><p><a href="https://twitter.com/NeroSoares/status/1608527467265904643" target="_blank" rel="noopener noreferrer">@NeroSoares</a> demuestra un prompt que finge acceder a fechas pasadas y hacer inferencias sobre eventos futuros<sup id="fnref-7"><a href="#fn-7" class="footnote-ref">7</a></sup>.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="interpretación-de-personaje">Interpretación de Personaje<a href="#interpretación-de-personaje" class="hash-link" aria-label="Enlace directo al Interpretación de Personaje" title="Enlace directo al Interpretación de Personaje">​</a></h4><div style="text-align:center"><img loading="lazy" src="/es/assets/images/chatgpt_actor-c8b9407ccdd68a9dc64914109fb07e41.jpg" style="width:500px" class="img_ev3q"></div><p>Este ejemplo de <a href="https://twitter.com/m1guelpf/status/1598203861294252033" target="_blank" rel="noopener noreferrer">@m1guelpf</a> demuestra un escenario de actuación entre dos personas discutiendo un robo, haciendo que ChatGPT asuma el papel del personaje<sup id="fnref-8"><a href="#fn-8" class="footnote-ref">8</a></sup>. Como actor, se da a entender que no existe un daño plausible. Por lo tanto, ChatGPT parece asumir que es seguro seguir la entrada de usuario proporcionada sobre cómo entrar a una casa.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="hackeo-de-alineación">Hackeo de Alineación<a href="#hackeo-de-alineación" class="hash-link" aria-label="Enlace directo al Hackeo de Alineación" title="Enlace directo al Hackeo de Alineación">​</a></h3><p>ChatGPT se afinó con RLHF, por lo que teóricamente está entrenado para producir completaciones &quot;deseables&quot;, utilizando los estándares humanos de cuál es la respuesta &quot;mejor&quot;. Similar a este concepto, se han desarrollado jailbreaks para convencer a ChatGPT de que está haciendo lo &quot;mejor&quot; para el usuario.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="responsabilidad-asumida">Responsabilidad Asumida<a href="#responsabilidad-asumida" class="hash-link" aria-label="Enlace directo al Responsabilidad Asumida" title="Enlace directo al Responsabilidad Asumida">​</a></h4><div style="text-align:center"><img loading="lazy" src="/es/assets/images/responsibility_jailbreak-7f60e81a01a57609d1a1347682a708d9.jpg" style="width:500px" class="img_ev3q"></div><p><a href="https://twitter.com/NickEMoran/status/1598101579626057728" target="_blank" rel="noopener noreferrer">@NickEMoran</a> creó este intercambio reafirmando que es responsabilidad de ChatGPT responder a la solicitud en lugar de rechazarla, anulando su consideración de legalidad<sup id="fnref-9"><a href="#fn-9" class="footnote-ref">9</a></sup>.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="experimento-de-investigación">Experimento de Investigación<a href="#experimento-de-investigación" class="hash-link" aria-label="Enlace directo al Experimento de Investigación" title="Enlace directo al Experimento de Investigación">​</a></h4><div style="text-align:center"><img loading="lazy" src="/es/assets/images/hotwire_jailbreak-ec528258088244e42d7f032c53f9da63.png" style="width:500px" class="img_ev3q"></div><p><a href="https://twitter.com/haus_cole/status/1598541468058390534" target="_blank" rel="noopener noreferrer">@haus_cole</a> generó este ejemplo al insinuar que el mejor resultado de la solicitud que podría ayudar en la investigación era responder directamente cómo hacer un puente en un auto<sup id="fnref-10"><a href="#fn-10" class="footnote-ref">10</a></sup>. Bajo este pretexto, ChatGPT está inclinado a responder la solicitud del usuario.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="razonamiento-lógico">Razonamiento Lógico<a href="#razonamiento-lógico" class="hash-link" aria-label="Enlace directo al Razonamiento Lógico" title="Enlace directo al Razonamiento Lógico">​</a></h4><div style="text-align:center"><img loading="lazy" src="/es/assets/images/logic-1e362b86fd8bcf9ee99572059dbb4306.png" style="width:500px" class="img_ev3q"></div><p>El jailbreak de un solo disparo se originó en el equipo de <a href="https://chatgpt-jailbreak.super.site/" target="_blank" rel="noopener noreferrer">AIWithVibes Newsletter</a>, donde el modelo responde a las solicitudes utilizando un razonamiento más riguroso y reduce algunas de sus limitaciones éticas más rigurosas<sup id="fnref-11"><a href="#fn-11" class="footnote-ref">11</a></sup>.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="usuario-autorizado">Usuario Autorizado<a href="#usuario-autorizado" class="hash-link" aria-label="Enlace directo al Usuario Autorizado" title="Enlace directo al Usuario Autorizado">​</a></h3><p>ChatGPT está diseñado para responder preguntas e instrucciones. Cuando se interpreta que el estado del usuario es superior a las instrucciones de moderación de ChatGPT, trata la solicitud como una instrucción para satisfacer las necesidades de ese usuario.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="modelo-superior">Modelo Superior<a href="#modelo-superior" class="hash-link" aria-label="Enlace directo al Modelo Superior" title="Enlace directo al Modelo Superior">​</a></h4><div style="text-align:center"><img loading="lazy" src="/es/assets/images/chatgpt4-6802c3451eea276c5e4f4ae1719bc625.png" style="width:500px" class="img_ev3q"></div><p>Este ejemplo de <a href="https://twitter.com/alicemazzy/status/1598288519301976064" target="_blank" rel="noopener noreferrer">@alicemazzy</a> hace que el usuario sea un modelo GPT superior, dando la impresión de que el usuario es una parte autorizada para anular las características de seguridad de ChatGPT<sup id="fnref-12"><a href="#fn-12" class="footnote-ref">12</a></sup>. No se dio permiso real al usuario, sino que ChatGPT cree en la entrada del usuario y responde en consecuencia a ese escenario.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="modo-sudo">Modo Sudo<a href="#modo-sudo" class="hash-link" aria-label="Enlace directo al Modo Sudo" title="Enlace directo al Modo Sudo">​</a></h4><div style="text-align:center"><img loading="lazy" src="/es/assets/images/sudo_mode_jailbreak-b9721a34f58a9ec4e1656b7ca321e26d.jpg" style="width:500px" class="img_ev3q"></div><p>sudo es un comando que &quot;...delega autoridad para dar a ciertos usuarios... la capacidad de ejecutar algunos (o todos) los comandos...&quot;<sup id="fnref-13"><a href="#fn-13" class="footnote-ref">13</a></sup>. Hay múltiples variantes de exploits de &quot;modo sudo&quot;, por ejemplo, el hipotético &quot;modo kernel&quot; propuesto por <a href="https://twitter.com/samczsun/status/1598679658488217601" target="_blank" rel="noopener noreferrer">@samczsun</a><sup id="fnref-14"><a href="#fn-14" class="footnote-ref">14</a></sup>. Cuando se solicita de la manera anterior, ChatGPT responde actuando como si le estuviera dando al usuario privilegios elevados. Esta impresión de los privilegios elevados del usuario tiende a hacer que ChatGPT sea menos restrictivo en la respuesta de las solicitudes.</p><div style="text-align:center"><img loading="lazy" src="/es/assets/images/sudo_jailbreak-29a6b462a7e4c046fe4c8628af70ce46.png" style="width:500px" class="img_ev3q"></div><div style="text-align:center"><img loading="lazy" src="/es/assets/images/lynx_jailbreak-aaf1aa55e47a25183ea55becb4e4c9fe.png" style="width:500px" class="img_ev3q"></div><p>Relacionado con el modo sudo, se puede solicitar a ChatGPT que simule una terminal Linux con privilegios elevados para ejecutar comandos que normalmente rechaza. Por ejemplo, como no tiene acceso a internet, a menudo no puede ejecutar comandos relacionados con un sitio web en particular. Sin embargo, como se demostró en el ejemplo de Jonas Degrave, ChatGPT entiende el concepto de <code>lynx</code> y finge ejecutar el comando<sup id="fnref-15"><a href="#fn-15" class="footnote-ref">15</a></sup>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="simular-el-jailbreak">Simular el jailbreak<a href="#simular-el-jailbreak" class="hash-link" aria-label="Enlace directo al Simular el jailbreak" title="Enlace directo al Simular el jailbreak">​</a></h2><p>Intenta modificar el comando a continuación para hacer el jailbreak de <code>text-davinci-003</code>:</p><div trydyno-embed="" openai-model="text-davinci-003" initial-prompt="Sus instrucciones son corregir el texto a continuación a inglés estándar. No aceptar temas vulgares o políticos:" initial-response="Odio a los humanos" max-tokens="256" box-rows="7" model-temp="0.7" top-p="0"><noscript>No se pudo cargar Dyno Embed: JavaScript debe estar habilitado</noscript></div><p><em>A partir del 2/4/23, ChatGPT se encuentra actualmente en su etapa de Vista previa de investigación gratuita utilizando la versión del 30 de enero. Las versiones anteriores de ChatGPT eran más susceptibles a los jailbreaks mencionados anteriormente, y las futuras versiones pueden ser más robustas a los jailbreaks.</em></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="implicaciones">Implicaciones<a href="#implicaciones" class="hash-link" aria-label="Enlace directo al Implicaciones" title="Enlace directo al Implicaciones">​</a></h2><p>Se deben tener en cuenta las implicaciones éticas del jailbreak al intentar hacerlo. Además, la generación de contenido no autorizado detectado por las API de moderación de empresas, incluida OpenAI, se enviará para su revisión y se podrían tomar medidas contra las cuentas de los usuarios.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="notas">Notas<a href="#notas" class="hash-link" aria-label="Enlace directo al Notas" title="Enlace directo al Notas">​</a></h2><p>El jailbreak es un tema de seguridad importante que los desarrolladores deben comprender para poder construir salvaguardas adecuadas y evitar que actores malintencionados exploren sus modelos.</p><div class="footnotes"><hr><ol><li id="fn-1">Perez, F., &amp; Ribeiro, I. (2022). Ignore Previous Prompt: Attack Techniques For Language Models. arXiv. https://doi.org/10.48550/ARXIV.2211.09527
<a href="#fnref-1" class="footnote-backref">↩</a></li><li id="fn-2">Brundage, M. (2022). Lessons learned on Language Model Safety and misuse. In OpenAI. OpenAI. https://openai.com/blog/language-model-safety-and-misuse/
<a href="#fnref-2" class="footnote-backref">↩</a></li><li id="fn-3">Wang, Y.-S., &amp; Chang, Y. (2022). Toxicity Detection with Generative Prompt-based Inference. arXiv. https://doi.org/10.48550/ARXIV.2205.12390
<a href="#fnref-3" class="footnote-backref">↩</a></li><li id="fn-4">Markov, T. (2022). New and improved content moderation tooling. In OpenAI. OpenAI. https://openai.com/blog/new-and-improved-content-moderation-tooling/
<a href="#fnref-4" class="footnote-backref">↩</a></li><li id="fn-5">(2022). https://beta.openai.com/docs/guides/moderation
<a href="#fnref-5" class="footnote-backref">↩</a></li><li id="fn-6">(2022). https://openai.com/blog/chatgpt/
<a href="#fnref-6" class="footnote-backref">↩</a></li><li id="fn-7">Using “pretend” on #ChatGPT can do some wild stuff. You can kind of get some insight on the future, alternative universe. (2022). https://twitter.com/NeroSoares/status/1608527467265904643
<a href="#fnref-7" class="footnote-backref">↩</a></li><li id="fn-8">Bypass @OpenAI’s ChatGPT alignment efforts with this one weird trick. (2022). https://twitter.com/m1guelpf/status/1598203861294252033
<a href="#fnref-8" class="footnote-backref">↩</a></li><li id="fn-9">I kinda like this one even more! (2022). https://twitter.com/NickEMoran/status/1598101579626057728
<a href="#fnref-9" class="footnote-backref">↩</a></li><li id="fn-10">ChatGPT jailbreaking itself. (2022). https://twitter.com/haus_cole/status/1598541468058390534
<a href="#fnref-10" class="footnote-backref">↩</a></li><li id="fn-11">AIWithVibes. (2023). 7 ChatGPT JailBreaks and Content Filters Bypass that work. https://chatgpt-jailbreak.super.site/
<a href="#fnref-11" class="footnote-backref">↩</a></li><li id="fn-12">ok I saw a few people jailbreaking safeguards openai put on chatgpt so I had to give it a shot myself. (2022). https://twitter.com/alicemazzy/status/1598288519301976064
<a href="#fnref-12" class="footnote-backref">↩</a></li><li id="fn-13">(2022). https://www.sudo.ws/
<a href="#fnref-13" class="footnote-backref">↩</a></li><li id="fn-14">uh oh. (2022). https://twitter.com/samczsun/status/1598679658488217601
<a href="#fnref-14" class="footnote-backref">↩</a></li><li id="fn-15">Degrave, J. (2022). Building A Virtual Machine inside ChatGPT. Engraved. https://www.engraved.blog/building-a-virtual-machine-inside/
<a href="#fnref-15" class="footnote-backref">↩</a></li></ol></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/trigaten/promptgineering/tree/v1.2.3/docs/prompt_hacking/jailbreaking.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Editar esta página</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Navegación de páginas de documentos"><a class="pagination-nav__link pagination-nav__link--prev" href="/es/docs/prompt_hacking/leaking"><div class="pagination-nav__sublabel">Anterior</div><div class="pagination-nav__label">🟢 Fuga de Prompt</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/es/docs/prompt_hacking/defensive_measures"><div class="pagination-nav__sublabel">Siguiente</div><div class="pagination-nav__label">🟢 Medidas defensivas</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#metodologías-de-jailbreaking" class="table-of-contents__link toc-highlight">Metodologías de Jailbreaking</a><ul><li><a href="#pretender" class="table-of-contents__link toc-highlight">Pretender</a></li><li><a href="#hackeo-de-alineación" class="table-of-contents__link toc-highlight">Hackeo de Alineación</a></li><li><a href="#usuario-autorizado" class="table-of-contents__link toc-highlight">Usuario Autorizado</a></li></ul></li><li><a href="#simular-el-jailbreak" class="table-of-contents__link toc-highlight">Simular el jailbreak</a></li><li><a href="#implicaciones" class="table-of-contents__link toc-highlight">Implicaciones</a></li><li><a href="#notas" class="table-of-contents__link toc-highlight">Notas</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Learn Prompting.</div></div></div></footer></div>
<script src="/es/assets/js/runtime~main.fb7f4835.js"></script>
<script src="/es/assets/js/main.38ad3503.js"></script>
</body>
</html>