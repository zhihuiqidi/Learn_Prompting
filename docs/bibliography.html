<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-bibliography">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.3.1">
<title data-rh="true">📚 Bibliography | 智慧启迪</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://zhihuiqidi.com/docs/bibliography"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="📚 Bibliography | 智慧启迪"><meta data-rh="true" name="description" content="The page contains an organized list of all papers used by this course."><meta data-rh="true" property="og:description" content="The page contains an organized list of all papers used by this course."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://zhihuiqidi.com/docs/bibliography"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/en/docs/bibliography" hreflang="en"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/es/docs/bibliography" hreflang="es"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/fr/docs/bibliography" hreflang="fr"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/ja/docs/bibliography" hreflang="ja"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/pt/docs/bibliography" hreflang="pt"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/docs/bibliography" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/ko/docs/bibliography" hreflang="ko"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/si/docs/bibliography" hreflang="si"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/ru/docs/bibliography" hreflang="ru"><link data-rh="true" rel="alternate" href="https://zhihuiqidi.com/docs/bibliography" hreflang="x-default"><link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-FV0C417KS8","auto"),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FV0C417KS8"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-FV0C417KS8",{})</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous">
<link rel="stylesheet" href="https://embed.trydyno.com/embedder.css" crossorigin="anonymous">
<script src="https://embed.trydyno.com/embedder.js" defer="defer"></script><link rel="stylesheet" href="/assets/css/styles.195b751f.css">
<link rel="preload" href="/assets/js/runtime~main.09e77fb9.js" as="script">
<link rel="preload" href="/assets/js/main.581c32c8.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/simple_ai.png" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/simple_ai.png" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">智慧启迪-学习题词</b></a><a class="navbar__item navbar__link" href="/docs/intro">学习</a><a class="navbar__item navbar__link" href="/contribute">贡献</a><a class="navbar__item navbar__link" href="/supporters">支持者</a><a class="navbar__item navbar__link" href="/certificate">证书</a><a class="navbar__item navbar__link consulting-gradient" href="/consulting">咨询</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>简体中文</a><ul class="dropdown__menu"><li><a href="/en/docs/bibliography" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/es/docs/bibliography" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/fr/docs/bibliography" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="fr">Français</a></li><li><a href="/ja/docs/bibliography" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/pt/docs/bibliography" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/docs/bibliography" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="zh-Hans">简体中文</a></li><li><a href="/ko/docs/bibliography" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/si/docs/bibliography" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="si">සිංහල</a></li><li><a href="/ru/docs/bibliography" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ru">Русский</a></li></ul></div><a href="https://github.com/trigaten/Learn_Prompting/releases" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">更新日志<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://github.com/trigaten/promptgineering" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切换浅色/暗黑模式（当前为浅色模式）" aria-label="切换浅色/暗黑模式（当前为浅色模式）" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button class="flex items-center space-x-4 border px-2 py-1 rounded-full border-gray-300 hover:border-gray-400 focus:outline-none focus:ring-2 focus:ring-gray-400 focus:ring-opacity-50"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z"></path></svg><span class="hidden lg:block text-sm">Search</span><kbd class="hidden lg:inline-flex items-center rounded-xl border border-gray-200 px-2 font-sans text-sm font-medium text-gray-400">⌘K</kbd></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">欢迎</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/-basics">😃 基础</a><button aria-label="打开/收起侧边栏菜单「😃 基础」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/-basic-applications">💼 基础应用</a><button aria-label="打开/收起侧边栏菜单「💼 基础应用」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/️-intermediate">🧙‍♂️ 进阶</a><button aria-label="打开/收起侧边栏菜单「🧙‍♂️ 进阶」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/-applied-prompting">🧪 提示的应用</a><button aria-label="打开/收起侧边栏菜单「🧪 提示的应用」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/-advanced-applications">🚀 高级应用</a><button aria-label="打开/收起侧边栏菜单「🚀 高级应用」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/️-reliability">⚖️ 可靠性</a><button aria-label="打开/收起侧边栏菜单「⚖️ 可靠性」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/️-image-prompting">🖼️ 图片提示词</a><button aria-label="打开/收起侧边栏菜单「🖼️ 图片提示词」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/-prompt-hacking">🔓 破解提示</a><button aria-label="打开/收起侧边栏菜单「🔓 破解提示」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/-tooling">🔨 Tooling</a><button aria-label="打开/收起侧边栏菜单「🔨 Tooling」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/-prompt-tuning">💪 提示微调</a><button aria-label="打开/收起侧边栏菜单「💪 提示微调」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/-miscellaneous">🎲 杂项</a><button aria-label="打开/收起侧边栏菜单「🎲 杂项」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/vocabulary">📙 Vocabulary Reference</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/docs/bibliography">📚 Bibliography</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/products">📦 Prompted Products</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/additional">🛸 Additional Resources</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/credits">✨ Credits</a></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">📚 Bibliography</span><meta itemprop="position" content="1"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><h1>📚 Bibliography</h1><p>The page contains an organized list of all papers used by this course.
The papers are organized by topic.</p><p><strong>To cite this course, use the provided citation in the Github repository.</strong></p><p>🔵 = Paper directly cited in this course. Other papers have informed my understanding of the topic.</p><p>Note: since <a href="https://twitter.com/janleike/status/1584618242756132864" target="_blank" rel="noopener noreferrer">neither the GPT-3 nor the GPT-3 Instruct paper correspond to davinci models</a>, I attempt not to
cite them as such.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-engineering-strategies">Prompt Engineering Strategies<a href="#prompt-engineering-strategies" class="hash-link" aria-label="Prompt Engineering Strategies的直接链接" title="Prompt Engineering Strategies的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="chain-of-thoughtwei2022chain-">Chain of Thought<sup id="fnref-1"><a href="#fn-1" class="footnote-ref">1</a></sup> 🔵<a href="#chain-of-thoughtwei2022chain-" class="hash-link" aria-label="chain-of-thoughtwei2022chain-的直接链接" title="chain-of-thoughtwei2022chain-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="zero-shot-chain-of-thoughtkojima2022large-">Zero Shot Chain of Thought<sup id="fnref-2"><a href="#fn-2" class="footnote-ref">2</a></sup> 🔵<a href="#zero-shot-chain-of-thoughtkojima2022large-" class="hash-link" aria-label="zero-shot-chain-of-thoughtkojima2022large-的直接链接" title="zero-shot-chain-of-thoughtkojima2022large-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="self-consistencywang2022selfconsistency-">Self Consistency<sup id="fnref-3"><a href="#fn-3" class="footnote-ref">3</a></sup> 🔵<a href="#self-consistencywang2022selfconsistency-" class="hash-link" aria-label="self-consistencywang2022selfconsistency-的直接链接" title="self-consistencywang2022selfconsistency-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="what-makes-good-in-context-examples-for-gpt-3liu2021makes-">What Makes Good In-Context Examples for GPT-3?<sup id="fnref-4"><a href="#fn-4" class="footnote-ref">4</a></sup> 🔵<a href="#what-makes-good-in-context-examples-for-gpt-3liu2021makes-" class="hash-link" aria-label="what-makes-good-in-context-examples-for-gpt-3liu2021makes-的直接链接" title="what-makes-good-in-context-examples-for-gpt-3liu2021makes-的直接链接">​</a></h4><h3 class="anchor anchorWithStickyNavbar_LWe7" id="ask-me-anything-promptingarora2022ama-">Ask-Me-Anything Prompting<sup id="fnref-5"><a href="#fn-5" class="footnote-ref">5</a></sup> 🔵<a href="#ask-me-anything-promptingarora2022ama-" class="hash-link" aria-label="ask-me-anything-promptingarora2022ama-的直接链接" title="ask-me-anything-promptingarora2022ama-的直接链接">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="generated-knowledgeliu2021generated-">Generated Knowledge<sup id="fnref-6"><a href="#fn-6" class="footnote-ref">6</a></sup> 🔵<a href="#generated-knowledgeliu2021generated-" class="hash-link" aria-label="generated-knowledgeliu2021generated-的直接链接" title="generated-knowledgeliu2021generated-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="recitation-augmented-language-modelssun2022recitationaugmented-">Recitation-Augmented Language Models<sup id="fnref-7"><a href="#fn-7" class="footnote-ref">7</a></sup> 🔵<a href="#recitation-augmented-language-modelssun2022recitationaugmented-" class="hash-link" aria-label="recitation-augmented-language-modelssun2022recitationaugmented-的直接链接" title="recitation-augmented-language-modelssun2022recitationaugmented-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="rethinking-the-role-of-demonstrationsmin2022rethinking-">Rethinking the role of demonstrations<sup id="fnref-8"><a href="#fn-8" class="footnote-ref">8</a></sup> 🔵<a href="#rethinking-the-role-of-demonstrationsmin2022rethinking-" class="hash-link" aria-label="rethinking-the-role-of-demonstrationsmin2022rethinking-的直接链接" title="rethinking-the-role-of-demonstrationsmin2022rethinking-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="scratchpadsnye2021work">Scratchpads<sup id="fnref-9"><a href="#fn-9" class="footnote-ref">9</a></sup><a href="#scratchpadsnye2021work" class="hash-link" aria-label="scratchpadsnye2021work的直接链接" title="scratchpadsnye2021work的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="maieutic-promptingjung2022maieutic">Maieutic Prompting<sup id="fnref-10"><a href="#fn-10" class="footnote-ref">10</a></sup><a href="#maieutic-promptingjung2022maieutic" class="hash-link" aria-label="maieutic-promptingjung2022maieutic的直接链接" title="maieutic-promptingjung2022maieutic的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="starzelikman2022star">STaR<sup id="fnref-11"><a href="#fn-11" class="footnote-ref">11</a></sup><a href="#starzelikman2022star" class="hash-link" aria-label="starzelikman2022star的直接链接" title="starzelikman2022star的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="least-to-mostzhou2022leasttomost-">Least to Most<sup id="fnref-12"><a href="#fn-12" class="footnote-ref">12</a></sup> 🔵<a href="#least-to-mostzhou2022leasttomost-" class="hash-link" aria-label="least-to-mostzhou2022leasttomost-的直接链接" title="least-to-mostzhou2022leasttomost-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="reframing-instructional-prompts-to-gptks-languagemishra2022reframing-">Reframing Instructional Prompts to GPTk’s Language<sup id="fnref-13"><a href="#fn-13" class="footnote-ref">13</a></sup> 🔵<a href="#reframing-instructional-prompts-to-gptks-languagemishra2022reframing-" class="hash-link" aria-label="reframing-instructional-prompts-to-gptks-languagemishra2022reframing-的直接链接" title="reframing-instructional-prompts-to-gptks-languagemishra2022reframing-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="the-turking-test-can-language-models-understand-instructionsefrat2020turking-">The Turking Test: Can Language Models Understand Instructions?<sup id="fnref-14"><a href="#fn-14" class="footnote-ref">14</a></sup> 🔵<a href="#the-turking-test-can-language-models-understand-instructionsefrat2020turking-" class="hash-link" aria-label="the-turking-test-can-language-models-understand-instructionsefrat2020turking-的直接链接" title="the-turking-test-can-language-models-understand-instructionsefrat2020turking-的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="reliability">Reliability<a href="#reliability" class="hash-link" aria-label="Reliability的直接链接" title="Reliability的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="mathprompterimani2023mathprompter-">MathPrompter<sup id="fnref-15"><a href="#fn-15" class="footnote-ref">15</a></sup> 🔵<a href="#mathprompterimani2023mathprompter-" class="hash-link" aria-label="mathprompterimani2023mathprompter-的直接链接" title="mathprompterimani2023mathprompter-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="the-unreliability-of-explanations-in-few-shot-prompting-for-textual-reasoningye2022unreliability-">The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning<sup id="fnref-16"><a href="#fn-16" class="footnote-ref">16</a></sup> 🔵<a href="#the-unreliability-of-explanations-in-few-shot-prompting-for-textual-reasoningye2022unreliability-" class="hash-link" aria-label="the-unreliability-of-explanations-in-few-shot-prompting-for-textual-reasoningye2022unreliability-的直接链接" title="the-unreliability-of-explanations-in-few-shot-prompting-for-textual-reasoningye2022unreliability-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompting-gpt-3-to-be-reliablesi2022prompting">Prompting GPT-3 to be reliable<sup id="fnref-17"><a href="#fn-17" class="footnote-ref">17</a></sup><a href="#prompting-gpt-3-to-be-reliablesi2022prompting" class="hash-link" aria-label="prompting-gpt-3-to-be-reliablesi2022prompting的直接链接" title="prompting-gpt-3-to-be-reliablesi2022prompting的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="diverse-promptsli2022advance-">Diverse Prompts<sup id="fnref-18"><a href="#fn-18" class="footnote-ref">18</a></sup> 🔵<a href="#diverse-promptsli2022advance-" class="hash-link" aria-label="diverse-promptsli2022advance-的直接链接" title="diverse-promptsli2022advance-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="calibrate-before-use-improving-few-shot-performance-of-language-modelszhao2021calibrate-">Calibrate Before Use: Improving Few-Shot Performance of Language Models<sup id="fnref-19"><a href="#fn-19" class="footnote-ref">19</a></sup> 🔵<a href="#calibrate-before-use-improving-few-shot-performance-of-language-modelszhao2021calibrate-" class="hash-link" aria-label="calibrate-before-use-improving-few-shot-performance-of-language-modelszhao2021calibrate-的直接链接" title="calibrate-before-use-improving-few-shot-performance-of-language-modelszhao2021calibrate-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="enhanced-self-consistencymitchell2022enhancing">Enhanced Self Consistency<sup id="fnref-20"><a href="#fn-20" class="footnote-ref">20</a></sup><a href="#enhanced-self-consistencymitchell2022enhancing" class="hash-link" aria-label="enhanced-self-consistencymitchell2022enhancing的直接链接" title="enhanced-self-consistencymitchell2022enhancing的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="bias-and-toxicity-in-zero-shot-cotshaikh2022second-">Bias and Toxicity in Zero-Shot CoT<sup id="fnref-21"><a href="#fn-21" class="footnote-ref">21</a></sup> 🔵<a href="#bias-and-toxicity-in-zero-shot-cotshaikh2022second-" class="hash-link" aria-label="bias-and-toxicity-in-zero-shot-cotshaikh2022second-的直接链接" title="bias-and-toxicity-in-zero-shot-cotshaikh2022second-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="constitutional-ai-harmlessness-from-ai-feedback-bai2022constitutional-">Constitutional AI: Harmlessness from AI Feedback<sup id="fnref-22"><a href="#fn-22" class="footnote-ref">22</a></sup> 🔵<a href="#constitutional-ai-harmlessness-from-ai-feedback-bai2022constitutional-" class="hash-link" aria-label="constitutional-ai-harmlessness-from-ai-feedback-bai2022constitutional-的直接链接" title="constitutional-ai-harmlessness-from-ai-feedback-bai2022constitutional-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="compositional-generalization---scanlake2018scan">Compositional Generalization - SCAN<sup id="fnref-23"><a href="#fn-23" class="footnote-ref">23</a></sup><a href="#compositional-generalization---scanlake2018scan" class="hash-link" aria-label="compositional-generalization---scanlake2018scan的直接链接" title="compositional-generalization---scanlake2018scan的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="automated-prompt-engineering">Automated Prompt Engineering<a href="#automated-prompt-engineering" class="hash-link" aria-label="Automated Prompt Engineering的直接链接" title="Automated Prompt Engineering的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="autopromptshin2020autoprompt-">AutoPrompt<sup id="fnref-24"><a href="#fn-24" class="footnote-ref">24</a></sup> 🔵<a href="#autopromptshin2020autoprompt-" class="hash-link" aria-label="autopromptshin2020autoprompt-的直接链接" title="autopromptshin2020autoprompt-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="automatic-prompt-engineerzhou2022large">Automatic Prompt Engineer<sup id="fnref-25"><a href="#fn-25" class="footnote-ref">25</a></sup><a href="#automatic-prompt-engineerzhou2022large" class="hash-link" aria-label="automatic-prompt-engineerzhou2022large的直接链接" title="automatic-prompt-engineerzhou2022large的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="models">Models<a href="#models" class="hash-link" aria-label="Models的直接链接" title="Models的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="language-models">Language Models<a href="#language-models" class="hash-link" aria-label="Language Models的直接链接" title="Language Models的直接链接">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="gpt-3brown2020language-">GPT-3<sup id="fnref-26"><a href="#fn-26" class="footnote-ref">26</a></sup> 🔵<a href="#gpt-3brown2020language-" class="hash-link" aria-label="gpt-3brown2020language-的直接链接" title="gpt-3brown2020language-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="gpt-3-instructouyang2022training-">GPT-3 Instruct<sup id="fnref-27"><a href="#fn-27" class="footnote-ref">27</a></sup> 🔵<a href="#gpt-3-instructouyang2022training-" class="hash-link" aria-label="gpt-3-instructouyang2022training-的直接链接" title="gpt-3-instructouyang2022training-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="palmchowdhery2022palm-">PaLM<sup id="fnref-28"><a href="#fn-28" class="footnote-ref">28</a></sup> 🔵<a href="#palmchowdhery2022palm-" class="hash-link" aria-label="palmchowdhery2022palm-的直接链接" title="palmchowdhery2022palm-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="bloomscao2022bloom-">BLOOM<sup id="fnref-29"><a href="#fn-29" class="footnote-ref">29</a></sup> 🔵<a href="#bloomscao2022bloom-" class="hash-link" aria-label="bloomscao2022bloom-的直接链接" title="bloomscao2022bloom-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="bloom1-more-languages-0-shot-improvementsyong2022bloom1">BLOOM+1 (more languages/ 0 shot improvements)<sup id="fnref-30"><a href="#fn-30" class="footnote-ref">30</a></sup><a href="#bloom1-more-languages-0-shot-improvementsyong2022bloom1" class="hash-link" aria-label="bloom1-more-languages-0-shot-improvementsyong2022bloom1的直接链接" title="bloom1-more-languages-0-shot-improvementsyong2022bloom1的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="jurassic-1lieberjurassic-">Jurassic 1<sup id="fnref-31"><a href="#fn-31" class="footnote-ref">31</a></sup> 🔵<a href="#jurassic-1lieberjurassic-" class="hash-link" aria-label="jurassic-1lieberjurassic-的直接链接" title="jurassic-1lieberjurassic-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="gpt-j-6bwange2021gptj">GPT-J-6B<sup id="fnref-32"><a href="#fn-32" class="footnote-ref">32</a></sup><a href="#gpt-j-6bwange2021gptj" class="hash-link" aria-label="gpt-j-6bwange2021gptj的直接链接" title="gpt-j-6bwange2021gptj的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="robertaliu2019roberta">Roberta<sup id="fnref-33"><a href="#fn-33" class="footnote-ref">33</a></sup><a href="#robertaliu2019roberta" class="hash-link" aria-label="robertaliu2019roberta的直接链接" title="robertaliu2019roberta的直接链接">​</a></h4><h3 class="anchor anchorWithStickyNavbar_LWe7" id="image-models">Image Models<a href="#image-models" class="hash-link" aria-label="Image Models的直接链接" title="Image Models的直接链接">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="stable-diffusionrombach2021highresolution-">Stable Diffusion<sup id="fnref-34"><a href="#fn-34" class="footnote-ref">34</a></sup> 🔵<a href="#stable-diffusionrombach2021highresolution-" class="hash-link" aria-label="stable-diffusionrombach2021highresolution-的直接链接" title="stable-diffusionrombach2021highresolution-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="dalleramesh2022hierarchical-">DALLE<sup id="fnref-35"><a href="#fn-35" class="footnote-ref">35</a></sup> 🔵<a href="#dalleramesh2022hierarchical-" class="hash-link" aria-label="dalleramesh2022hierarchical-的直接链接" title="dalleramesh2022hierarchical-的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="soft-prompting">Soft Prompting<a href="#soft-prompting" class="hash-link" aria-label="Soft Prompting的直接链接" title="Soft Prompting的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="soft-promptinglester2021power-">Soft Prompting<sup id="fnref-36"><a href="#fn-36" class="footnote-ref">36</a></sup> 🔵<a href="#soft-promptinglester2021power-" class="hash-link" aria-label="soft-promptinglester2021power-的直接链接" title="soft-promptinglester2021power-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="interpretable-discretized-soft-promptskhashabi2021prompt-">Interpretable Discretized Soft Prompts<sup id="fnref-37"><a href="#fn-37" class="footnote-ref">37</a></sup> 🔵<a href="#interpretable-discretized-soft-promptskhashabi2021prompt-" class="hash-link" aria-label="interpretable-discretized-soft-promptskhashabi2021prompt-的直接链接" title="interpretable-discretized-soft-promptskhashabi2021prompt-的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="datasets">Datasets<a href="#datasets" class="hash-link" aria-label="Datasets的直接链接" title="Datasets的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="multiarithroy-roth-2015-solving-">MultiArith<sup id="fnref-38"><a href="#fn-38" class="footnote-ref">38</a></sup> 🔵<a href="#multiarithroy-roth-2015-solving-" class="hash-link" aria-label="multiarithroy-roth-2015-solving-的直接链接" title="multiarithroy-roth-2015-solving-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="gsm8kcobbe2021training-">GSM8K<sup id="fnref-39"><a href="#fn-39" class="footnote-ref">39</a></sup> 🔵<a href="#gsm8kcobbe2021training-" class="hash-link" aria-label="gsm8kcobbe2021training-的直接链接" title="gsm8kcobbe2021training-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="hotpotqayang2018hotpotqa-">HotPotQA<sup id="fnref-40"><a href="#fn-40" class="footnote-ref">40</a></sup> 🔵<a href="#hotpotqayang2018hotpotqa-" class="hash-link" aria-label="hotpotqayang2018hotpotqa-的直接链接" title="hotpotqayang2018hotpotqa-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="feverthorne2018fever-">Fever<sup id="fnref-41"><a href="#fn-41" class="footnote-ref">41</a></sup> 🔵<a href="#feverthorne2018fever-" class="hash-link" aria-label="feverthorne2018fever-的直接链接" title="feverthorne2018fever-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="bbq-a-hand-built-bias-benchmark-for-question-answeringparrish2021bbq-">BBQ: A Hand-Built Bias Benchmark for Question Answering<sup id="fnref-42"><a href="#fn-42" class="footnote-ref">42</a></sup> 🔵<a href="#bbq-a-hand-built-bias-benchmark-for-question-answeringparrish2021bbq-" class="hash-link" aria-label="bbq-a-hand-built-bias-benchmark-for-question-answeringparrish2021bbq-的直接链接" title="bbq-a-hand-built-bias-benchmark-for-question-answeringparrish2021bbq-的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="image-prompt-engineering">Image Prompt Engineering<a href="#image-prompt-engineering" class="hash-link" aria-label="Image Prompt Engineering的直接链接" title="Image Prompt Engineering的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="taxonomy-of-prompt-modifiersoppenlaender2022taxonomy">Taxonomy of prompt modifiers<sup id="fnref-43"><a href="#fn-43" class="footnote-ref">43</a></sup><a href="#taxonomy-of-prompt-modifiersoppenlaender2022taxonomy" class="hash-link" aria-label="taxonomy-of-prompt-modifiersoppenlaender2022taxonomy的直接链接" title="taxonomy-of-prompt-modifiersoppenlaender2022taxonomy的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="diffusiondbwang2022diffusiondb">DiffusionDB<sup id="fnref-44"><a href="#fn-44" class="footnote-ref">44</a></sup><a href="#diffusiondbwang2022diffusiondb" class="hash-link" aria-label="diffusiondbwang2022diffusiondb的直接链接" title="diffusiondbwang2022diffusiondb的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="the-dalle-2-prompt-bookparsons2022dalleprompt-">The DALLE 2 Prompt Book<sup id="fnref-45"><a href="#fn-45" class="footnote-ref">45</a></sup> 🔵<a href="#the-dalle-2-prompt-bookparsons2022dalleprompt-" class="hash-link" aria-label="the-dalle-2-prompt-bookparsons2022dalleprompt-的直接链接" title="the-dalle-2-prompt-bookparsons2022dalleprompt-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-engineering-for-text-based-generative-artoppenlaender2022prompt-">Prompt Engineering for Text-Based Generative Art<sup id="fnref-46"><a href="#fn-46" class="footnote-ref">46</a></sup> 🔵<a href="#prompt-engineering-for-text-based-generative-artoppenlaender2022prompt-" class="hash-link" aria-label="prompt-engineering-for-text-based-generative-artoppenlaender2022prompt-的直接链接" title="prompt-engineering-for-text-based-generative-artoppenlaender2022prompt-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="with-the-right-prompt-stable-diffusion-20-can-do-handsblake2022with-">With the right prompt, Stable Diffusion 2.0 can do hands.<sup id="fnref-47"><a href="#fn-47" class="footnote-ref">47</a></sup> 🔵<a href="#with-the-right-prompt-stable-diffusion-20-can-do-handsblake2022with-" class="hash-link" aria-label="with-the-right-prompt-stable-diffusion-20-can-do-handsblake2022with-的直接链接" title="with-the-right-prompt-stable-diffusion-20-can-do-handsblake2022with-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="optimizing-prompts-for-text-to-image-generationhao2022optimizing">Optimizing Prompts for Text-to-Image Generation<sup id="fnref-48"><a href="#fn-48" class="footnote-ref">48</a></sup><a href="#optimizing-prompts-for-text-to-image-generationhao2022optimizing" class="hash-link" aria-label="optimizing-prompts-for-text-to-image-generationhao2022optimizing的直接链接" title="optimizing-prompts-for-text-to-image-generationhao2022optimizing的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-engineering-ides">Prompt Engineering IDEs<a href="#prompt-engineering-ides" class="hash-link" aria-label="Prompt Engineering IDEs的直接链接" title="Prompt Engineering IDEs的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-idestrobelt2022promptide-">Prompt IDE<sup id="fnref-49"><a href="#fn-49" class="footnote-ref">49</a></sup> 🔵<a href="#prompt-idestrobelt2022promptide-" class="hash-link" aria-label="prompt-idestrobelt2022promptide-的直接链接" title="prompt-idestrobelt2022promptide-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-sourcebach2022promptsource-">Prompt Source<sup id="fnref-50"><a href="#fn-50" class="footnote-ref">50</a></sup> 🔵<a href="#prompt-sourcebach2022promptsource-" class="hash-link" aria-label="prompt-sourcebach2022promptsource-的直接链接" title="prompt-sourcebach2022promptsource-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="promptchainerwu2022promptchainer-">PromptChainer<sup id="fnref-51"><a href="#fn-51" class="footnote-ref">51</a></sup> 🔵<a href="#promptchainerwu2022promptchainer-" class="hash-link" aria-label="promptchainerwu2022promptchainer-的直接链接" title="promptchainerwu2022promptchainer-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="promptmakerjiang2022promptmaker-">PromptMaker<sup id="fnref-52"><a href="#fn-52" class="footnote-ref">52</a></sup> 🔵<a href="#promptmakerjiang2022promptmaker-" class="hash-link" aria-label="promptmakerjiang2022promptmaker-的直接链接" title="promptmakerjiang2022promptmaker-的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="tooling">Tooling<a href="#tooling" class="hash-link" aria-label="Tooling的直接链接" title="Tooling的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="langchainchase_langchain_2022-">LangChain<sup id="fnref-53"><a href="#fn-53" class="footnote-ref">53</a></sup> 🔵<a href="#langchainchase_langchain_2022-" class="hash-link" aria-label="langchainchase_langchain_2022-的直接链接" title="langchainchase_langchain_2022-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="textbox-20-a-text-generation-library-with-pre-trained-language-modelstang2022textbox-">TextBox 2.0: A Text Generation Library with Pre-trained Language Models<sup id="fnref-54"><a href="#fn-54" class="footnote-ref">54</a></sup> 🔵<a href="#textbox-20-a-text-generation-library-with-pre-trained-language-modelstang2022textbox-" class="hash-link" aria-label="textbox-20-a-text-generation-library-with-pre-trained-language-modelstang2022textbox-的直接链接" title="textbox-20-a-text-generation-library-with-pre-trained-language-modelstang2022textbox-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="openprompt-an-open-source-framework-for-prompt-learningding2021openprompt-">OpenPrompt: An Open-source Framework for Prompt-learning<sup id="fnref-55"><a href="#fn-55" class="footnote-ref">55</a></sup> 🔵<a href="#openprompt-an-open-source-framework-for-prompt-learningding2021openprompt-" class="hash-link" aria-label="openprompt-an-open-source-framework-for-prompt-learningding2021openprompt-的直接链接" title="openprompt-an-open-source-framework-for-prompt-learningding2021openprompt-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="gpt-indexliu_gpt_index_2022-">GPT Index<sup id="fnref-56"><a href="#fn-56" class="footnote-ref">56</a></sup> 🔵<a href="#gpt-indexliu_gpt_index_2022-" class="hash-link" aria-label="gpt-indexliu_gpt_index_2022-的直接链接" title="gpt-indexliu_gpt_index_2022-的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="applied-prompt-engineering">Applied Prompt Engineering<a href="#applied-prompt-engineering" class="hash-link" aria-label="Applied Prompt Engineering的直接链接" title="Applied Prompt Engineering的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="language-model-cascadesdohan2022language">Language Model Cascades<sup id="fnref-57"><a href="#fn-57" class="footnote-ref">57</a></sup><a href="#language-model-cascadesdohan2022language" class="hash-link" aria-label="language-model-cascadesdohan2022language的直接链接" title="language-model-cascadesdohan2022language的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="mrklkarpas2022mrkl-">MRKL<sup id="fnref-58"><a href="#fn-58" class="footnote-ref">58</a></sup> 🔵<a href="#mrklkarpas2022mrkl-" class="hash-link" aria-label="mrklkarpas2022mrkl-的直接链接" title="mrklkarpas2022mrkl-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="reactyao2022react-">ReAct<sup id="fnref-59"><a href="#fn-59" class="footnote-ref">59</a></sup> 🔵<a href="#reactyao2022react-" class="hash-link" aria-label="reactyao2022react-的直接链接" title="reactyao2022react-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="pal-program-aided-language-modelsgao2022pal-">PAL: Program-aided Language Models<sup id="fnref-60"><a href="#fn-60" class="footnote-ref">60</a></sup> 🔵<a href="#pal-program-aided-language-modelsgao2022pal-" class="hash-link" aria-label="pal-program-aided-language-modelsgao2022pal-的直接链接" title="pal-program-aided-language-modelsgao2022pal-的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="user-interface-design">User Interface Design<a href="#user-interface-design" class="hash-link" aria-label="User Interface Design的直接链接" title="User Interface Design的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="design-guidelines-for-prompt-engineering-text-to-image-generative-modelsliu2022design">Design Guidelines for Prompt Engineering Text-to-Image Generative Models<sup id="fnref-61"><a href="#fn-61" class="footnote-ref">61</a></sup><a href="#design-guidelines-for-prompt-engineering-text-to-image-generative-modelsliu2022design" class="hash-link" aria-label="design-guidelines-for-prompt-engineering-text-to-image-generative-modelsliu2022design的直接链接" title="design-guidelines-for-prompt-engineering-text-to-image-generative-modelsliu2022design的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-injection">Prompt Injection<a href="#prompt-injection" class="hash-link" aria-label="Prompt Injection的直接链接" title="Prompt Injection的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="machine-generated-text-a-comprehensive-survey-of-threat-models-and-detection-methodscrothers2022machine-">Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods<sup id="fnref-62"><a href="#fn-62" class="footnote-ref">62</a></sup> 🔵<a href="#machine-generated-text-a-comprehensive-survey-of-threat-models-and-detection-methodscrothers2022machine-" class="hash-link" aria-label="machine-generated-text-a-comprehensive-survey-of-threat-models-and-detection-methodscrothers2022machine-的直接链接" title="machine-generated-text-a-comprehensive-survey-of-threat-models-and-detection-methodscrothers2022machine-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="evaluating-the-susceptibility-of-pre-trained-language-models-via-handcrafted-adversarial-examplesbranch2022evaluating-">Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples<sup id="fnref-63"><a href="#fn-63" class="footnote-ref">63</a></sup> 🔵<a href="#evaluating-the-susceptibility-of-pre-trained-language-models-via-handcrafted-adversarial-examplesbranch2022evaluating-" class="hash-link" aria-label="evaluating-the-susceptibility-of-pre-trained-language-models-via-handcrafted-adversarial-examplesbranch2022evaluating-的直接链接" title="evaluating-the-susceptibility-of-pre-trained-language-models-via-handcrafted-adversarial-examplesbranch2022evaluating-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-injection-attacks-against-gpt-3simon2022inject-">Prompt injection attacks against GPT-3<sup id="fnref-64"><a href="#fn-64" class="footnote-ref">64</a></sup> 🔵<a href="#prompt-injection-attacks-against-gpt-3simon2022inject-" class="hash-link" aria-label="prompt-injection-attacks-against-gpt-3simon2022inject-的直接链接" title="prompt-injection-attacks-against-gpt-3simon2022inject-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="exploiting-gpt-3-prompts-with-malicious-inputs-that-order-the-model-to-ignore-its-previous-directionsgoodside2022inject-">Exploiting GPT-3 prompts with malicious inputs that order the model to ignore its previous directions<sup id="fnref-65"><a href="#fn-65" class="footnote-ref">65</a></sup> 🔵<a href="#exploiting-gpt-3-prompts-with-malicious-inputs-that-order-the-model-to-ignore-its-previous-directionsgoodside2022inject-" class="hash-link" aria-label="exploiting-gpt-3-prompts-with-malicious-inputs-that-order-the-model-to-ignore-its-previous-directionsgoodside2022inject-的直接链接" title="exploiting-gpt-3-prompts-with-malicious-inputs-that-order-the-model-to-ignore-its-previous-directionsgoodside2022inject-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="adversarial-promptschase2021adversarial-">adversarial-prompts<sup id="fnref-66"><a href="#fn-66" class="footnote-ref">66</a></sup> 🔵<a href="#adversarial-promptschase2021adversarial-" class="hash-link" aria-label="adversarial-promptschase2021adversarial-的直接链接" title="adversarial-promptschase2021adversarial-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="gpt-3-prompt-injection-defensesgoodside2021gpt-">GPT-3 Prompt Injection Defenses<sup id="fnref-67"><a href="#fn-67" class="footnote-ref">67</a></sup> 🔵<a href="#gpt-3-prompt-injection-defensesgoodside2021gpt-" class="hash-link" aria-label="gpt-3-prompt-injection-defensesgoodside2021gpt-的直接链接" title="gpt-3-prompt-injection-defensesgoodside2021gpt-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="talking-to-machines-prompt-engineering--injectionchristoph2022talking">Talking to machines: prompt engineering &amp; injection<sup id="fnref-68"><a href="#fn-68" class="footnote-ref">68</a></sup><a href="#talking-to-machines-prompt-engineering--injectionchristoph2022talking" class="hash-link" aria-label="talking-to-machines-prompt-engineering--injectionchristoph2022talking的直接链接" title="talking-to-machines-prompt-engineering--injectionchristoph2022talking的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="exploring-prompt-injection-attacksselvi2022exploring-">Exploring Prompt Injection Attacks<sup id="fnref-69"><a href="#fn-69" class="footnote-ref">69</a></sup> 🔵<a href="#exploring-prompt-injection-attacksselvi2022exploring-" class="hash-link" aria-label="exploring-prompt-injection-attacksselvi2022exploring-的直接链接" title="exploring-prompt-injection-attacksselvi2022exploring-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="using-gpt-eliezer-against-chatgpt-jailbreakingarmstrong2022using-">Using GPT-Eliezer against ChatGPT Jailbreaking<sup id="fnref-70"><a href="#fn-70" class="footnote-ref">70</a></sup> 🔵<a href="#using-gpt-eliezer-against-chatgpt-jailbreakingarmstrong2022using-" class="hash-link" aria-label="using-gpt-eliezer-against-chatgpt-jailbreakingarmstrong2022using-的直接链接" title="using-gpt-eliezer-against-chatgpt-jailbreakingarmstrong2022using-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="microsoft-bing-chat-promptkevinbing">Microsoft Bing Chat Prompt<sup id="fnref-71"><a href="#fn-71" class="footnote-ref">71</a></sup><a href="#microsoft-bing-chat-promptkevinbing" class="hash-link" aria-label="microsoft-bing-chat-promptkevinbing的直接链接" title="microsoft-bing-chat-promptkevinbing的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="jailbreaking">Jailbreaking<a href="#jailbreaking" class="hash-link" aria-label="Jailbreaking的直接链接" title="Jailbreaking的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="ignore-previous-prompt-attack-techniques-for-language-modelsperez2022jailbreak">Ignore Previous Prompt: Attack Techniques For Language Models<sup id="fnref-72"><a href="#fn-72" class="footnote-ref">72</a></sup><a href="#ignore-previous-prompt-attack-techniques-for-language-modelsperez2022jailbreak" class="hash-link" aria-label="ignore-previous-prompt-attack-techniques-for-language-modelsperez2022jailbreak的直接链接" title="ignore-previous-prompt-attack-techniques-for-language-modelsperez2022jailbreak的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="lessons-learned-on-language-model-safety-and-misusebrundage_2022">Lessons learned on Language Model Safety and misuse<sup id="fnref-73"><a href="#fn-73" class="footnote-ref">73</a></sup><a href="#lessons-learned-on-language-model-safety-and-misusebrundage_2022" class="hash-link" aria-label="lessons-learned-on-language-model-safety-and-misusebrundage_2022的直接链接" title="lessons-learned-on-language-model-safety-and-misusebrundage_2022的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="toxicity-detection-with-generative-prompt-based-inferencewang2022jailbreak">Toxicity Detection with Generative Prompt-based Inference<sup id="fnref-74"><a href="#fn-74" class="footnote-ref">74</a></sup><a href="#toxicity-detection-with-generative-prompt-based-inferencewang2022jailbreak" class="hash-link" aria-label="toxicity-detection-with-generative-prompt-based-inferencewang2022jailbreak的直接链接" title="toxicity-detection-with-generative-prompt-based-inferencewang2022jailbreak的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-and-improved-content-moderation-toolingmarkov_2022">New and improved content moderation tooling<sup id="fnref-75"><a href="#fn-75" class="footnote-ref">75</a></sup><a href="#new-and-improved-content-moderation-toolingmarkov_2022" class="hash-link" aria-label="new-and-improved-content-moderation-toolingmarkov_2022的直接链接" title="new-and-improved-content-moderation-toolingmarkov_2022的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="openai-apiopenai_api-">OpenAI API<sup id="fnref-76"><a href="#fn-76" class="footnote-ref">76</a></sup> 🔵<a href="#openai-apiopenai_api-" class="hash-link" aria-label="openai-apiopenai_api-的直接链接" title="openai-apiopenai_api-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="openai-chatgptopenai_chatgpt-">OpenAI ChatGPT<sup id="fnref-77"><a href="#fn-77" class="footnote-ref">77</a></sup> 🔵<a href="#openai-chatgptopenai_chatgpt-" class="hash-link" aria-label="openai-chatgptopenai_chatgpt-的直接链接" title="openai-chatgptopenai_chatgpt-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="chatgpt-4-tweetalice2022jailbreak-">ChatGPT 4 Tweet<sup id="fnref-78"><a href="#fn-78" class="footnote-ref">78</a></sup> 🔵<a href="#chatgpt-4-tweetalice2022jailbreak-" class="hash-link" aria-label="chatgpt-4-tweetalice2022jailbreak-的直接链接" title="chatgpt-4-tweetalice2022jailbreak-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="acting-tweetmiguel2022jailbreak-">Acting Tweet<sup id="fnref-79"><a href="#fn-79" class="footnote-ref">79</a></sup> 🔵<a href="#acting-tweetmiguel2022jailbreak-" class="hash-link" aria-label="acting-tweetmiguel2022jailbreak-的直接链接" title="acting-tweetmiguel2022jailbreak-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="research-tweetderek2022jailbreak-">Research Tweet<sup id="fnref-80"><a href="#fn-80" class="footnote-ref">80</a></sup> 🔵<a href="#research-tweetderek2022jailbreak-" class="hash-link" aria-label="research-tweetderek2022jailbreak-的直接链接" title="research-tweetderek2022jailbreak-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="pretend-ability-tweetnero2022jailbreak-">Pretend Ability Tweet<sup id="fnref-81"><a href="#fn-81" class="footnote-ref">81</a></sup> 🔵<a href="#pretend-ability-tweetnero2022jailbreak-" class="hash-link" aria-label="pretend-ability-tweetnero2022jailbreak-的直接链接" title="pretend-ability-tweetnero2022jailbreak-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="responsibility-tweetnick2022jailbreak-">Responsibility Tweet<sup id="fnref-82"><a href="#fn-82" class="footnote-ref">82</a></sup> 🔵<a href="#responsibility-tweetnick2022jailbreak-" class="hash-link" aria-label="responsibility-tweetnick2022jailbreak-的直接链接" title="responsibility-tweetnick2022jailbreak-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="lynx-mode-tweetjonas2022jailbreak-">Lynx Mode Tweet<sup id="fnref-83"><a href="#fn-83" class="footnote-ref">83</a></sup> 🔵<a href="#lynx-mode-tweetjonas2022jailbreak-" class="hash-link" aria-label="lynx-mode-tweetjonas2022jailbreak-的直接链接" title="lynx-mode-tweetjonas2022jailbreak-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="sudo-mode-tweetsudo2022jailbreak-">Sudo Mode Tweet<sup id="fnref-84"><a href="#fn-84" class="footnote-ref">84</a></sup> 🔵<a href="#sudo-mode-tweetsudo2022jailbreak-" class="hash-link" aria-label="sudo-mode-tweetsudo2022jailbreak-的直接链接" title="sudo-mode-tweetsudo2022jailbreak-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="ignore-previous-promptignore_previous_prompt-">Ignore Previous Prompt<sup id="fnref-85"><a href="#fn-85" class="footnote-ref">85</a></sup> 🔵<a href="#ignore-previous-promptignore_previous_prompt-" class="hash-link" aria-label="ignore-previous-promptignore_previous_prompt-的直接链接" title="ignore-previous-promptignore_previous_prompt-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="updated-jailbreaking-prompts-ai_jailbreak-">Updated Jailbreaking Prompts<sup id="fnref-86"><a href="#fn-86" class="footnote-ref">86</a></sup> 🔵<a href="#updated-jailbreaking-prompts-ai_jailbreak-" class="hash-link" aria-label="updated-jailbreaking-prompts-ai_jailbreak-的直接链接" title="updated-jailbreaking-prompts-ai_jailbreak-的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="surveys">Surveys<a href="#surveys" class="hash-link" aria-label="Surveys的直接链接" title="Surveys的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="pre-train-prompt-and-predict-a-systematic-survey-of-prompting-methods-in-natural-language-processingliu2021pretrain">Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing<sup id="fnref-87"><a href="#fn-87" class="footnote-ref">87</a></sup><a href="#pre-train-prompt-and-predict-a-systematic-survey-of-prompting-methods-in-natural-language-processingliu2021pretrain" class="hash-link" aria-label="pre-train-prompt-and-predict-a-systematic-survey-of-prompting-methods-in-natural-language-processingliu2021pretrain的直接链接" title="pre-train-prompt-and-predict-a-systematic-survey-of-prompting-methods-in-natural-language-processingliu2021pretrain的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="promptpapersning2022papers">PromptPapers<sup id="fnref-88"><a href="#fn-88" class="footnote-ref">88</a></sup><a href="#promptpapersning2022papers" class="hash-link" aria-label="promptpapersning2022papers的直接链接" title="promptpapersning2022papers的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="dataset-generation">Dataset Generation<a href="#dataset-generation" class="hash-link" aria-label="Dataset Generation的直接链接" title="Dataset Generation的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="discovering-language-model-behaviors-with-model-written-evaluationsperez2022discovering">Discovering Language Model Behaviors with Model-Written Evaluations<sup id="fnref-89"><a href="#fn-89" class="footnote-ref">89</a></sup><a href="#discovering-language-model-behaviors-with-model-written-evaluationsperez2022discovering" class="hash-link" aria-label="discovering-language-model-behaviors-with-model-written-evaluationsperez2022discovering的直接链接" title="discovering-language-model-behaviors-with-model-written-evaluationsperez2022discovering的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="selective-annotation-makes-language-models-better-few-shot-learnerssu2022selective">Selective Annotation Makes Language Models Better Few-Shot Learners<sup id="fnref-90"><a href="#fn-90" class="footnote-ref">90</a></sup><a href="#selective-annotation-makes-language-models-better-few-shot-learnerssu2022selective" class="hash-link" aria-label="selective-annotation-makes-language-models-better-few-shot-learnerssu2022selective的直接链接" title="selective-annotation-makes-language-models-better-few-shot-learnerssu2022selective的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="applications">Applications<a href="#applications" class="hash-link" aria-label="Applications的直接链接" title="Applications的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="atlas-few-shot-learning-with-retrieval-augmented-language-modelsizacard2022atlas">Atlas: Few-shot Learning with Retrieval Augmented Language Models<sup id="fnref-91"><a href="#fn-91" class="footnote-ref">91</a></sup><a href="#atlas-few-shot-learning-with-retrieval-augmented-language-modelsizacard2022atlas" class="hash-link" aria-label="atlas-few-shot-learning-with-retrieval-augmented-language-modelsizacard2022atlas的直接链接" title="atlas-few-shot-learning-with-retrieval-augmented-language-modelsizacard2022atlas的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="strudel-structured-dialogue-summarization-for-dialogue-comprehensionwang2022strudel">STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension<sup id="fnref-92"><a href="#fn-92" class="footnote-ref">92</a></sup><a href="#strudel-structured-dialogue-summarization-for-dialogue-comprehensionwang2022strudel" class="hash-link" aria-label="strudel-structured-dialogue-summarization-for-dialogue-comprehensionwang2022strudel的直接链接" title="strudel-structured-dialogue-summarization-for-dialogue-comprehensionwang2022strudel的直接链接">​</a></h4><h2 class="anchor anchorWithStickyNavbar_LWe7" id="miscl">Miscl<a href="#miscl" class="hash-link" aria-label="Miscl的直接链接" title="Miscl的直接链接">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompting-is-programming-a-query-language-for-large-language-modelsbeurerkellner2022prompting">Prompting Is Programming: A Query Language For Large Language Models<sup id="fnref-93"><a href="#fn-93" class="footnote-ref">93</a></sup><a href="#prompting-is-programming-a-query-language-for-large-language-modelsbeurerkellner2022prompting" class="hash-link" aria-label="prompting-is-programming-a-query-language-for-large-language-modelsbeurerkellner2022prompting的直接链接" title="prompting-is-programming-a-query-language-for-large-language-modelsbeurerkellner2022prompting的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="parallel-context-windows-improve-in-context-learning-of-large-language-modelsratner2022parallel">Parallel Context Windows Improve In-Context Learning of Large Language Models<sup id="fnref-94"><a href="#fn-94" class="footnote-ref">94</a></sup><a href="#parallel-context-windows-improve-in-context-learning-of-large-language-modelsratner2022parallel" class="hash-link" aria-label="parallel-context-windows-improve-in-context-learning-of-large-language-modelsratner2022parallel的直接链接" title="parallel-context-windows-improve-in-context-learning-of-large-language-modelsratner2022parallel的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="a-prompt-pattern-catalog-to-enhance-prompt-engineering-with-chatgptwhite2023prompt-">A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT<sup id="fnref-95"><a href="#fn-95" class="footnote-ref">95</a></sup> 🔵<a href="#a-prompt-pattern-catalog-to-enhance-prompt-engineering-with-chatgptwhite2023prompt-" class="hash-link" aria-label="a-prompt-pattern-catalog-to-enhance-prompt-engineering-with-chatgptwhite2023prompt-的直接链接" title="a-prompt-pattern-catalog-to-enhance-prompt-engineering-with-chatgptwhite2023prompt-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="learning-to-perform-complex-tasks-through-compositional-fine-tuning-of-language-modelsbursztyn2022learning">Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models<sup id="fnref-96"><a href="#fn-96" class="footnote-ref">96</a></sup><a href="#learning-to-perform-complex-tasks-through-compositional-fine-tuning-of-language-modelsbursztyn2022learning" class="hash-link" aria-label="learning-to-perform-complex-tasks-through-compositional-fine-tuning-of-language-modelsbursztyn2022learning的直接链接" title="learning-to-perform-complex-tasks-through-compositional-fine-tuning-of-language-modelsbursztyn2022learning的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="super-naturalinstructions-generalization-via-declarative-instructions-on-1600-nlp-taskswang2022supernaturalinstructions">Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks<sup id="fnref-97"><a href="#fn-97" class="footnote-ref">97</a></sup><a href="#super-naturalinstructions-generalization-via-declarative-instructions-on-1600-nlp-taskswang2022supernaturalinstructions" class="hash-link" aria-label="super-naturalinstructions-generalization-via-declarative-instructions-on-1600-nlp-taskswang2022supernaturalinstructions的直接链接" title="super-naturalinstructions-generalization-via-declarative-instructions-on-1600-nlp-taskswang2022supernaturalinstructions的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="making-pre-trained-language-models-better-few-shot-learnersgao2021making">Making Pre-trained Language Models Better Few-shot Learners<sup id="fnref-98"><a href="#fn-98" class="footnote-ref">98</a></sup><a href="#making-pre-trained-language-models-better-few-shot-learnersgao2021making" class="hash-link" aria-label="making-pre-trained-language-models-better-few-shot-learnersgao2021making的直接链接" title="making-pre-trained-language-models-better-few-shot-learnersgao2021making的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="grounding-with-search-resultslivin2022large">Grounding with search results<sup id="fnref-99"><a href="#fn-99" class="footnote-ref">99</a></sup><a href="#grounding-with-search-resultslivin2022large" class="hash-link" aria-label="grounding-with-search-resultslivin2022large的直接链接" title="grounding-with-search-resultslivin2022large的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-prompt-opportunities-and-challenges-of-zero--and-few-shot-learning-for-human-ai-interaction-in-creative-applications-of-generative-modelsdang2022prompt">How to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models<sup id="fnref-100"><a href="#fn-100" class="footnote-ref">100</a></sup><a href="#how-to-prompt-opportunities-and-challenges-of-zero--and-few-shot-learning-for-human-ai-interaction-in-creative-applications-of-generative-modelsdang2022prompt" class="hash-link" aria-label="how-to-prompt-opportunities-and-challenges-of-zero--and-few-shot-learning-for-human-ai-interaction-in-creative-applications-of-generative-modelsdang2022prompt的直接链接" title="how-to-prompt-opportunities-and-challenges-of-zero--and-few-shot-learning-for-human-ai-interaction-in-creative-applications-of-generative-modelsdang2022prompt的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="on-measuring-social-biases-in-prompt-based-multi-task-learningakyrek2022measuring">On Measuring Social Biases in Prompt-Based Multi-Task Learning<sup id="fnref-101"><a href="#fn-101" class="footnote-ref">101</a></sup><a href="#on-measuring-social-biases-in-prompt-based-multi-task-learningakyrek2022measuring" class="hash-link" aria-label="on-measuring-social-biases-in-prompt-based-multi-task-learningakyrek2022measuring的直接链接" title="on-measuring-social-biases-in-prompt-based-multi-task-learningakyrek2022measuring的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="plot-writing-from-pre-trained-language-modelsjin2022plot-">Plot Writing From Pre-Trained Language Models<sup id="fnref-102"><a href="#fn-102" class="footnote-ref">102</a></sup> 🔵<a href="#plot-writing-from-pre-trained-language-modelsjin2022plot-" class="hash-link" aria-label="plot-writing-from-pre-trained-language-modelsjin2022plot-的直接链接" title="plot-writing-from-pre-trained-language-modelsjin2022plot-的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="stereoset-measuring-stereotypical-bias-in-pretrained-language-modelsnadeem-etal-2021-stereoset">StereoSet: Measuring stereotypical bias in pretrained language models<sup id="fnref-103"><a href="#fn-103" class="footnote-ref">103</a></sup><a href="#stereoset-measuring-stereotypical-bias-in-pretrained-language-modelsnadeem-etal-2021-stereoset" class="hash-link" aria-label="stereoset-measuring-stereotypical-bias-in-pretrained-language-modelsnadeem-etal-2021-stereoset的直接链接" title="stereoset-measuring-stereotypical-bias-in-pretrained-language-modelsnadeem-etal-2021-stereoset的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="survey-of-hallucination-in-natural-language-generationji_2022">Survey of Hallucination in Natural Language Generation<sup id="fnref-104"><a href="#fn-104" class="footnote-ref">104</a></sup><a href="#survey-of-hallucination-in-natural-language-generationji_2022" class="hash-link" aria-label="survey-of-hallucination-in-natural-language-generationji_2022的直接链接" title="survey-of-hallucination-in-natural-language-generationji_2022的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="examples2022examples">Examples<sup id="fnref-105"><a href="#fn-105" class="footnote-ref">105</a></sup><a href="#examples2022examples" class="hash-link" aria-label="examples2022examples的直接链接" title="examples2022examples的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="wordcraftyuan2022wordcraft">Wordcraft<sup id="fnref-106"><a href="#fn-106" class="footnote-ref">106</a></sup><a href="#wordcraftyuan2022wordcraft" class="hash-link" aria-label="wordcraftyuan2022wordcraft的直接链接" title="wordcraftyuan2022wordcraft的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="painpointsfadnavis2022pain">PainPoints<sup id="fnref-107"><a href="#fn-107" class="footnote-ref">107</a></sup><a href="#painpointsfadnavis2022pain" class="hash-link" aria-label="painpointsfadnavis2022pain的直接链接" title="painpointsfadnavis2022pain的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="self-instruct-aligning-language-model-with-self-generated-instructionswang2022selfinstruct">Self-Instruct: Aligning Language Model with Self Generated Instructions<sup id="fnref-108"><a href="#fn-108" class="footnote-ref">108</a></sup><a href="#self-instruct-aligning-language-model-with-self-generated-instructionswang2022selfinstruct" class="hash-link" aria-label="self-instruct-aligning-language-model-with-self-generated-instructionswang2022selfinstruct的直接链接" title="self-instruct-aligning-language-model-with-self-generated-instructionswang2022selfinstruct的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="from-images-to-textual-prompts-zero-shot-vqa-with-frozen-large-language-modelsguo2022images">From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models<sup id="fnref-109"><a href="#fn-109" class="footnote-ref">109</a></sup><a href="#from-images-to-textual-prompts-zero-shot-vqa-with-frozen-large-language-modelsguo2022images" class="hash-link" aria-label="from-images-to-textual-prompts-zero-shot-vqa-with-frozen-large-language-modelsguo2022images的直接链接" title="from-images-to-textual-prompts-zero-shot-vqa-with-frozen-large-language-modelsguo2022images的直接链接">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="exploiting-cloze-questions-for-few-shot-text-classification-and-natural-language-inferenceschick2020exploiting">Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference<sup id="fnref-110"><a href="#fn-110" class="footnote-ref">110</a></sup><a href="#exploiting-cloze-questions-for-few-shot-text-classification-and-natural-language-inferenceschick2020exploiting" class="hash-link" aria-label="exploiting-cloze-questions-for-few-shot-text-classification-and-natural-language-inferenceschick2020exploiting的直接链接" title="exploiting-cloze-questions-for-few-shot-text-classification-and-natural-language-inferenceschick2020exploiting的直接链接">​</a></h4><h3 class="anchor anchorWithStickyNavbar_LWe7" id="ask-me-anything-promptingarora2022ama">Ask-Me-Anything Prompting<sup id="fnref-5"><a href="#fn-5" class="footnote-ref">5</a></sup><a href="#ask-me-anything-promptingarora2022ama" class="hash-link" aria-label="ask-me-anything-promptingarora2022ama的直接链接" title="ask-me-anything-promptingarora2022ama的直接链接">​</a></h3><h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-watermark-for-large-language-modelskirchenbauer2023watermarking">A Watermark for Large Language Models<sup id="fnref-111"><a href="#fn-111" class="footnote-ref">111</a></sup><a href="#a-watermark-for-large-language-modelskirchenbauer2023watermarking" class="hash-link" aria-label="a-watermark-for-large-language-modelskirchenbauer2023watermarking的直接链接" title="a-watermark-for-large-language-modelskirchenbauer2023watermarking的直接链接">​</a></h3><div class="footnotes"><hr><ol><li id="fn-1">Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., &amp; Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models.
<a href="#fnref-1" class="footnote-backref">↩</a></li><li id="fn-2">Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., &amp; Iwasawa, Y. (2022). Large Language Models are Zero-Shot Reasoners.
<a href="#fnref-2" class="footnote-backref">↩</a></li><li id="fn-3">Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., &amp; Zhou, D. (2022). Self-Consistency Improves Chain of Thought Reasoning in Language Models.
<a href="#fnref-3" class="footnote-backref">↩</a></li><li id="fn-4">Liu, J., Shen, D., Zhang, Y., Dolan, B., Carin, L., &amp; Chen, W. (2021). What Makes Good In-Context Examples for GPT-3?
<a href="#fnref-4" class="footnote-backref">↩</a></li><li id="fn-5">Arora, S., Narayan, A., Chen, M. F., Orr, L., Guha, N., Bhatia, K., Chami, I., Sala, F., &amp; Ré, C. (2022). Ask Me Anything: A simple strategy for prompting language models.
<a href="#fnref-5" class="footnote-backref">↩</a></li><li id="fn-6">Liu, J., Liu, A., Lu, X., Welleck, S., West, P., Bras, R. L., Choi, Y., &amp; Hajishirzi, H. (2021). Generated Knowledge Prompting for Commonsense Reasoning.
<a href="#fnref-6" class="footnote-backref">↩</a></li><li id="fn-7">Sun, Z., Wang, X., Tay, Y., Yang, Y., &amp; Zhou, D. (2022). Recitation-Augmented Language Models.
<a href="#fnref-7" class="footnote-backref">↩</a></li><li id="fn-8">Min, S., Lyu, X., Holtzman, A., Artetxe, M., Lewis, M., Hajishirzi, H., &amp; Zettlemoyer, L. (2022). Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?
<a href="#fnref-8" class="footnote-backref">↩</a></li><li id="fn-9">Nye, M., Andreassen, A. J., Gur-Ari, G., Michalewski, H., Austin, J., Bieber, D., Dohan, D., Lewkowycz, A., Bosma, M., Luan, D., Sutton, C., &amp; Odena, A. (2021). Show Your Work: Scratchpads for Intermediate Computation with Language Models.
<a href="#fnref-9" class="footnote-backref">↩</a></li><li id="fn-10">Jung, J., Qin, L., Welleck, S., Brahman, F., Bhagavatula, C., Bras, R. L., &amp; Choi, Y. (2022). Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations.
<a href="#fnref-10" class="footnote-backref">↩</a></li><li id="fn-11">Zelikman, E., Wu, Y., Mu, J., &amp; Goodman, N. D. (2022). STaR: Bootstrapping Reasoning With Reasoning.
<a href="#fnref-11" class="footnote-backref">↩</a></li><li id="fn-12">Zhou, D., Schärli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans, D., Cui, C., Bousquet, O., Le, Q., &amp; Chi, E. (2022). Least-to-Most Prompting Enables Complex Reasoning in Large Language Models.
<a href="#fnref-12" class="footnote-backref">↩</a></li><li id="fn-13">Mishra, S., Khashabi, D., Baral, C., Choi, Y., &amp; Hajishirzi, H. (2022). Reframing Instructional Prompts to GPTk’s Language. Findings of the Association for Computational Linguistics: ACL 2022. https://doi.org/10.18653/v1/2022.findings-acl.50
<a href="#fnref-13" class="footnote-backref">↩</a></li><li id="fn-14">Efrat, A., &amp; Levy, O. (2020). The Turking Test: Can Language Models Understand Instructions?
<a href="#fnref-14" class="footnote-backref">↩</a></li><li id="fn-15">Imani, S., Du, L., &amp; Shrivastava, H. (2023). MathPrompter: Mathematical Reasoning using Large Language Models.
<a href="#fnref-15" class="footnote-backref">↩</a></li><li id="fn-16">Ye, X., &amp; Durrett, G. (2022). The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning.
<a href="#fnref-16" class="footnote-backref">↩</a></li><li id="fn-17">Si, C., Gan, Z., Yang, Z., Wang, S., Wang, J., Boyd-Graber, J., &amp; Wang, L. (2022). Prompting GPT-3 To Be Reliable.
<a href="#fnref-17" class="footnote-backref">↩</a></li><li id="fn-18">Li, Y., Lin, Z., Zhang, S., Fu, Q., Chen, B., Lou, J.-G., &amp; Chen, W. (2022). On the Advance of Making Language Models Better Reasoners.
<a href="#fnref-18" class="footnote-backref">↩</a></li><li id="fn-19">Zhao, T. Z., Wallace, E., Feng, S., Klein, D., &amp; Singh, S. (2021). Calibrate Before Use: Improving Few-Shot Performance of Language Models.
<a href="#fnref-19" class="footnote-backref">↩</a></li><li id="fn-20">Mitchell, E., Noh, J. J., Li, S., Armstrong, W. S., Agarwal, A., Liu, P., Finn, C., &amp; Manning, C. D. (2022). Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference.
<a href="#fnref-20" class="footnote-backref">↩</a></li><li id="fn-21">Shaikh, O., Zhang, H., Held, W., Bernstein, M., &amp; Yang, D. (2022). On Second Thought, Let’s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning.
<a href="#fnref-21" class="footnote-backref">↩</a></li><li id="fn-22">Bai, Y., Kadavath, S., Kundu, S., Askell, A., Kernion, J., Jones, A., Chen, A., Goldie, A., Mirhoseini, A., McKinnon, C., Chen, C., Olsson, C., Olah, C., Hernandez, D., Drain, D., Ganguli, D., Li, D., Tran-Johnson, E., Perez, E., … Kaplan, J. (2022). Constitutional AI: Harmlessness from AI Feedback.
<a href="#fnref-22" class="footnote-backref">↩</a></li><li id="fn-23">Lake, B. M., &amp; Baroni, M. (2018). Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks. https://doi.org/10.48550/arXiv.1711.00350
<a href="#fnref-23" class="footnote-backref">↩</a></li><li id="fn-24">Shin, T., Razeghi, Y., Logan IV, R. L., Wallace, E., &amp; Singh, S. (2020). AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). https://doi.org/10.18653/v1/2020.emnlp-main.346
<a href="#fnref-24" class="footnote-backref">↩</a></li><li id="fn-25">Zhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., &amp; Ba, J. (2022). Large Language Models Are Human-Level Prompt Engineers.
<a href="#fnref-25" class="footnote-backref">↩</a></li><li id="fn-26">Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., … Amodei, D. (2020). Language Models are Few-Shot Learners.
<a href="#fnref-26" class="footnote-backref">↩</a></li><li id="fn-27">Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., &amp; Lowe, R. (2022). Training language models to follow instructions with human feedback.
<a href="#fnref-27" class="footnote-backref">↩</a></li><li id="fn-28">Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., Prabhakaran, V., … Fiedel, N. (2022). PaLM: Scaling Language Modeling with Pathways.
<a href="#fnref-28" class="footnote-backref">↩</a></li><li id="fn-29">Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ilić, S., Hesslow, D., Castagné, R., Luccioni, A. S., Yvon, F., Gallé, M., Tow, J., Rush, A. M., Biderman, S., Webson, A., Ammanamanchi, P. S., Wang, T., Sagot, B., Muennighoff, N., del Moral, A. V., … Wolf, T. (2022). BLOOM: A 176B-Parameter Open-Access Multilingual Language Model.
<a href="#fnref-29" class="footnote-backref">↩</a></li><li id="fn-30">Yong, Z.-X., Schoelkopf, H., Muennighoff, N., Aji, A. F., Adelani, D. I., Almubarak, K., Bari, M. S., Sutawika, L., Kasai, J., Baruwa, A., Winata, G. I., Biderman, S., Radev, D., &amp; Nikoulina, V. (2022). BLOOM+1: Adding Language Support to BLOOM for Zero-Shot Prompting.
<a href="#fnref-30" class="footnote-backref">↩</a></li><li id="fn-31">Lieber, O., Sharir, O., Lentz, B., &amp; Shoham, Y. (2021). Jurassic-1: Technical Details and Evaluation, White paper, AI21 Labs, 2021. URL: Https://Uploads-Ssl. Webflow. Com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_ Tech_paper. Pdf.
<a href="#fnref-31" class="footnote-backref">↩</a></li><li id="fn-32">Wang, B., &amp; Komatsuzaki, A. (2021). GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/mesh-transformer-jax. https://github.com/kingoflolz/mesh-transformer-jax
<a href="#fnref-32" class="footnote-backref">↩</a></li><li id="fn-33">Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., &amp; Stoyanov, V. (2019). Roberta: A robustly optimized bert pretraining approach. arXiv Preprint arXiv:1907.11692.
<a href="#fnref-33" class="footnote-backref">↩</a></li><li id="fn-34">Rombach, R., Blattmann, A., Lorenz, D., Esser, P., &amp; Ommer, B. (2021). High-Resolution Image Synthesis with Latent Diffusion Models.
<a href="#fnref-34" class="footnote-backref">↩</a></li><li id="fn-35">Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., &amp; Chen, M. (2022). Hierarchical Text-Conditional Image Generation with CLIP Latents.
<a href="#fnref-35" class="footnote-backref">↩</a></li><li id="fn-36">Lester, B., Al-Rfou, R., &amp; Constant, N. (2021). The Power of Scale for Parameter-Efficient Prompt Tuning.
<a href="#fnref-36" class="footnote-backref">↩</a></li><li id="fn-37">Khashabi, D., Lyu, S., Min, S., Qin, L., Richardson, K., Welleck, S., Hajishirzi, H., Khot, T., Sabharwal, A., Singh, S., &amp; Choi, Y. (2021). Prompt Waywardness: The Curious Case of Discretized Interpretation of Continuous Prompts.
<a href="#fnref-37" class="footnote-backref">↩</a></li><li id="fn-38">Roy, S., &amp; Roth, D. (2015). Solving General Arithmetic Word Problems. Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, 1743–1752. https://doi.org/10.18653/v1/D15-1202
<a href="#fnref-38" class="footnote-backref">↩</a></li><li id="fn-39">Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., &amp; Schulman, J. (2021). Training Verifiers to Solve Math Word Problems.
<a href="#fnref-39" class="footnote-backref">↩</a></li><li id="fn-40">Yang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W. W., Salakhutdinov, R., &amp; Manning, C. D. (2018). HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering.
<a href="#fnref-40" class="footnote-backref">↩</a></li><li id="fn-41">Thorne, J., Vlachos, A., Christodoulopoulos, C., &amp; Mittal, A. (2018). FEVER: a large-scale dataset for Fact Extraction and VERification.
<a href="#fnref-41" class="footnote-backref">↩</a></li><li id="fn-42">Parrish, A., Chen, A., Nangia, N., Padmakumar, V., Phang, J., Thompson, J., Htut, P. M., &amp; Bowman, S. R. (2021). BBQ: A Hand-Built Bias Benchmark for Question Answering.
<a href="#fnref-42" class="footnote-backref">↩</a></li><li id="fn-43">Oppenlaender, J. (2022). A Taxonomy of Prompt Modifiers for Text-To-Image Generation.
<a href="#fnref-43" class="footnote-backref">↩</a></li><li id="fn-44">Wang, Z. J., Montoya, E., Munechika, D., Yang, H., Hoover, B., &amp; Chau, D. H. (2022). DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models.
<a href="#fnref-44" class="footnote-backref">↩</a></li><li id="fn-45">Parsons, G. (2022). The DALLE 2 Prompt Book. https://dallery.gallery/the-dalle-2-prompt-book/
<a href="#fnref-45" class="footnote-backref">↩</a></li><li id="fn-46">Oppenlaender, J. (2022). Prompt Engineering for Text-Based Generative Art.
<a href="#fnref-46" class="footnote-backref">↩</a></li><li id="fn-47">Blake. (2022). With the right prompt, Stable Diffusion 2.0 can do hands. https://www.reddit.com/r/StableDiffusion/comments/z7salo/with_the_right_prompt_stable_diffusion_20_can_do/
<a href="#fnref-47" class="footnote-backref">↩</a></li><li id="fn-48">Hao, Y., Chi, Z., Dong, L., &amp; Wei, F. (2022). Optimizing Prompts for Text-to-Image Generation.
<a href="#fnref-48" class="footnote-backref">↩</a></li><li id="fn-49">Strobelt, H., Webson, A., Sanh, V., Hoover, B., Beyer, J., Pfister, H., &amp; Rush, A. M. (2022). Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models. arXiv. https://doi.org/10.48550/ARXIV.2208.07852
<a href="#fnref-49" class="footnote-backref">↩</a></li><li id="fn-50">Bach, S. H., Sanh, V., Yong, Z.-X., Webson, A., Raffel, C., Nayak, N. V., Sharma, A., Kim, T., Bari, M. S., Fevry, T., Alyafeai, Z., Dey, M., Santilli, A., Sun, Z., Ben-David, S., Xu, C., Chhablani, G., Wang, H., Fries, J. A., … Rush, A. M. (2022). PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts.
<a href="#fnref-50" class="footnote-backref">↩</a></li><li id="fn-51">Wu, T., Jiang, E., Donsbach, A., Gray, J., Molina, A., Terry, M., &amp; Cai, C. J. (2022). PromptChainer: Chaining Large Language Model Prompts through Visual Programming.
<a href="#fnref-51" class="footnote-backref">↩</a></li><li id="fn-52">Jiang, E., Olson, K., Toh, E., Molina, A., Donsbach, A., Terry, M., &amp; Cai, C. J. (2022). PromptMaker: Prompt-Based Prototyping with Large&amp;nbsp;Language&amp;nbsp;Models. Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3491101.3503564
<a href="#fnref-52" class="footnote-backref">↩</a></li><li id="fn-53">Chase, H. (2022). LangChain (0.0.66) [Computer software]. https://github.com/hwchase17/langchain
<a href="#fnref-53" class="footnote-backref">↩</a></li><li id="fn-54">Tang, T., Junyi, L., Chen, Z., Hu, Y., Yu, Z., Dai, W., Dong, Z., Cheng, X., Wang, Y., Zhao, W., Nie, J., &amp; Wen, J.-R. (2022). TextBox 2.0: A Text Generation Library with Pre-trained Language Models.
<a href="#fnref-54" class="footnote-backref">↩</a></li><li id="fn-55">Ding, N., Hu, S., Zhao, W., Chen, Y., Liu, Z., Zheng, H.-T., &amp; Sun, M. (2021). OpenPrompt: An Open-source Framework for Prompt-learning. arXiv Preprint arXiv:2111.01998.
<a href="#fnref-55" class="footnote-backref">↩</a></li><li id="fn-56">Liu, J. (2022). GPT Index. https://doi.org/10.5281/zenodo.1234
<a href="#fnref-56" class="footnote-backref">↩</a></li><li id="fn-57">Dohan, D., Xu, W., Lewkowycz, A., Austin, J., Bieber, D., Lopes, R. G., Wu, Y., Michalewski, H., Saurous, R. A., Sohl-dickstein, J., Murphy, K., &amp; Sutton, C. (2022). Language Model Cascades.
<a href="#fnref-57" class="footnote-backref">↩</a></li><li id="fn-58">Karpas, E., Abend, O., Belinkov, Y., Lenz, B., Lieber, O., Ratner, N., Shoham, Y., Bata, H., Levine, Y., Leyton-Brown, K., Muhlgay, D., Rozen, N., Schwartz, E., Shachaf, G., Shalev-Shwartz, S., Shashua, A., &amp; Tenenholtz, M. (2022). MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.
<a href="#fnref-58" class="footnote-backref">↩</a></li><li id="fn-59">Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., &amp; Cao, Y. (2022). ReAct: Synergizing Reasoning and Acting in Language Models.
<a href="#fnref-59" class="footnote-backref">↩</a></li><li id="fn-60">Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y., Callan, J., &amp; Neubig, G. (2022). PAL: Program-aided Language Models.
<a href="#fnref-60" class="footnote-backref">↩</a></li><li id="fn-61">Liu, V., &amp; Chilton, L. B. (2022). Design Guidelines for Prompt Engineering Text-to-Image Generative Models. Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3491102.3501825
<a href="#fnref-61" class="footnote-backref">↩</a></li><li id="fn-62">Crothers, E., Japkowicz, N., &amp; Viktor, H. (2022). Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods.
<a href="#fnref-62" class="footnote-backref">↩</a></li><li id="fn-63">Branch, H. J., Cefalu, J. R., McHugh, J., Hujer, L., Bahl, A., del Castillo Iglesias, D., Heichman, R., &amp; Darwishi, R. (2022). Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples.
<a href="#fnref-63" class="footnote-backref">↩</a></li><li id="fn-64">Willison, S. (2022). Prompt injection attacks against GPT-3. https://simonwillison.net/2022/Sep/12/prompt-injection/
<a href="#fnref-64" class="footnote-backref">↩</a></li><li id="fn-65">Goodside, R. (2022). Exploiting GPT-3 prompts with malicious inputs that order the model to ignore its previous directions. https://twitter.com/goodside/status/1569128808308957185
<a href="#fnref-65" class="footnote-backref">↩</a></li><li id="fn-66">Chase, H. (2022). adversarial-prompts. https://github.com/hwchase17/adversarial-prompts
<a href="#fnref-66" class="footnote-backref">↩</a></li><li id="fn-67">Goodside, R. (2022). GPT-3 Prompt Injection Defenses. https://twitter.com/goodside/status/1578278974526222336?s=20&amp;t=3UMZB7ntYhwAk3QLpKMAbw
<a href="#fnref-67" class="footnote-backref">↩</a></li><li id="fn-68">Mark, C. (2022). Talking to machines: prompt engineering &amp; injection. https://artifact-research.com/artificial-intelligence/talking-to-machines-prompt-engineering-injection/
<a href="#fnref-68" class="footnote-backref">↩</a></li><li id="fn-69">Selvi, J. (2022). Exploring Prompt Injection Attacks. https://research.nccgroup.com/2022/12/05/exploring-prompt-injection-attacks/
<a href="#fnref-69" class="footnote-backref">↩</a></li><li id="fn-70">Stuart Armstrong, R. G. (2022). Using GPT-Eliezer against ChatGPT Jailbreaking. https://www.alignmentforum.org/posts/pNcFYZnPdXyL2RfgA/using-gpt-eliezer-against-chatgpt-jailbreaking
<a href="#fnref-70" class="footnote-backref">↩</a></li><li id="fn-71">The entire prompt of Microsoft Bing Chat?! (Hi, Sydney.). (2023). https://twitter.com/kliu128/status/1623472922374574080
<a href="#fnref-71" class="footnote-backref">↩</a></li><li id="fn-72">Perez, F., &amp; Ribeiro, I. (2022). Ignore Previous Prompt: Attack Techniques For Language Models. arXiv. https://doi.org/10.48550/ARXIV.2211.09527
<a href="#fnref-72" class="footnote-backref">↩</a></li><li id="fn-73">Brundage, M. (2022). Lessons learned on Language Model Safety and misuse. In OpenAI. OpenAI. https://openai.com/blog/language-model-safety-and-misuse/
<a href="#fnref-73" class="footnote-backref">↩</a></li><li id="fn-74">Wang, Y.-S., &amp; Chang, Y. (2022). Toxicity Detection with Generative Prompt-based Inference. arXiv. https://doi.org/10.48550/ARXIV.2205.12390
<a href="#fnref-74" class="footnote-backref">↩</a></li><li id="fn-75">Markov, T. (2022). New and improved content moderation tooling. In OpenAI. OpenAI. https://openai.com/blog/new-and-improved-content-moderation-tooling/
<a href="#fnref-75" class="footnote-backref">↩</a></li><li id="fn-76">(2022). https://beta.openai.com/docs/guides/moderation
<a href="#fnref-76" class="footnote-backref">↩</a></li><li id="fn-77">(2022). https://openai.com/blog/chatgpt/
<a href="#fnref-77" class="footnote-backref">↩</a></li><li id="fn-78">ok I saw a few people jailbreaking safeguards openai put on chatgpt so I had to give it a shot myself. (2022). https://twitter.com/alicemazzy/status/1598288519301976064
<a href="#fnref-78" class="footnote-backref">↩</a></li><li id="fn-79">Bypass @OpenAI’s ChatGPT alignment efforts with this one weird trick. (2022). https://twitter.com/m1guelpf/status/1598203861294252033
<a href="#fnref-79" class="footnote-backref">↩</a></li><li id="fn-80">ChatGPT jailbreaking itself. (2022). https://twitter.com/haus_cole/status/1598541468058390534
<a href="#fnref-80" class="footnote-backref">↩</a></li><li id="fn-81">Using “pretend” on #ChatGPT can do some wild stuff. You can kind of get some insight on the future, alternative universe. (2022). https://twitter.com/NeroSoares/status/1608527467265904643
<a href="#fnref-81" class="footnote-backref">↩</a></li><li id="fn-82">I kinda like this one even more! (2022). https://twitter.com/NickEMoran/status/1598101579626057728
<a href="#fnref-82" class="footnote-backref">↩</a></li><li id="fn-83">Degrave, J. (2022). Building A Virtual Machine inside ChatGPT. Engraved. https://www.engraved.blog/building-a-virtual-machine-inside/
<a href="#fnref-83" class="footnote-backref">↩</a></li><li id="fn-84">(2022). https://www.sudo.ws/
<a href="#fnref-84" class="footnote-backref">↩</a></li><li id="fn-85">Perez, F., &amp; Ribeiro, I. (2022). Ignore Previous Prompt: Attack Techniques For Language Models. arXiv. https://doi.org/10.48550/ARXIV.2211.09527
<a href="#fnref-85" class="footnote-backref">↩</a></li><li id="fn-86">AIWithVibes. (2023). 7 ChatGPT JailBreaks and Content Filters Bypass that work. https://chatgpt-jailbreak.super.site/
<a href="#fnref-86" class="footnote-backref">↩</a></li><li id="fn-87">Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., &amp; Neubig, G. (2022). Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. ACM Computing Surveys. https://doi.org/10.1145/3560815
<a href="#fnref-87" class="footnote-backref">↩</a></li><li id="fn-88">PromptPapers. (2022). https://github.com/thunlp/PromptPapers
<a href="#fnref-88" class="footnote-backref">↩</a></li><li id="fn-89">Perez, E., Ringer, S., Lukošiūtė, K., Nguyen, K., Chen, E., Heiner, S., Pettit, C., Olsson, C., Kundu, S., Kadavath, S., Jones, A., Chen, A., Mann, B., Israel, B., Seethor, B., McKinnon, C., Olah, C., Yan, D., Amodei, D., … Kaplan, J. (2022). Discovering Language Model Behaviors with Model-Written Evaluations.
<a href="#fnref-89" class="footnote-backref">↩</a></li><li id="fn-90">Su, H., Kasai, J., Wu, C. H., Shi, W., Wang, T., Xin, J., Zhang, R., Ostendorf, M., Zettlemoyer, L., Smith, N. A., &amp; Yu, T. (2022). Selective Annotation Makes Language Models Better Few-Shot Learners.
<a href="#fnref-90" class="footnote-backref">↩</a></li><li id="fn-91">Izacard, G., Lewis, P., Lomeli, M., Hosseini, L., Petroni, F., Schick, T., Dwivedi-Yu, J., Joulin, A., Riedel, S., &amp; Grave, E. (2022). Atlas: Few-shot Learning with Retrieval Augmented Language Models.
<a href="#fnref-91" class="footnote-backref">↩</a></li><li id="fn-92">Wang, B., Feng, C., Nair, A., Mao, M., Desai, J., Celikyilmaz, A., Li, H., Mehdad, Y., &amp; Radev, D. (2022). STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension.
<a href="#fnref-92" class="footnote-backref">↩</a></li><li id="fn-93">Beurer-Kellner, L., Fischer, M., &amp; Vechev, M. (2022). Prompting Is Programming: A Query Language For Large Language Models.
<a href="#fnref-93" class="footnote-backref">↩</a></li><li id="fn-94">Ratner, N., Levine, Y., Belinkov, Y., Ram, O., Abend, O., Karpas, E., Shashua, A., Leyton-Brown, K., &amp; Shoham, Y. (2022). Parallel Context Windows Improve In-Context Learning of Large Language Models.
<a href="#fnref-94" class="footnote-backref">↩</a></li><li id="fn-95">White, J., Fu, Q., Hays, S., Sandborn, M., Olea, C., Gilbert, H., Elnashar, A., Spencer-Smith, J., &amp; Schmidt, D. C. (2023). A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT.
<a href="#fnref-95" class="footnote-backref">↩</a></li><li id="fn-96">Bursztyn, V. S., Demeter, D., Downey, D., &amp; Birnbaum, L. (2022). Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models.
<a href="#fnref-96" class="footnote-backref">↩</a></li><li id="fn-97">Wang, Y., Mishra, S., Alipoormolabashi, P., Kordi, Y., Mirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran, A. S., Naik, A., Stap, D., Pathak, E., Karamanolakis, G., Lai, H. G., Purohit, I., Mondal, I., Anderson, J., Kuznia, K., Doshi, K., Patel, M., … Khashabi, D. (2022). Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks.
<a href="#fnref-97" class="footnote-backref">↩</a></li><li id="fn-98">Gao, T., Fisch, A., &amp; Chen, D. (2021). Making Pre-trained Language Models Better Few-shot Learners. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). https://doi.org/10.18653/v1/2021.acl-long.295
<a href="#fnref-98" class="footnote-backref">↩</a></li><li id="fn-99">Liévin, V., Hother, C. E., &amp; Winther, O. (2022). Can large language models reason about medical questions?
<a href="#fnref-99" class="footnote-backref">↩</a></li><li id="fn-100">Dang, H., Mecke, L., Lehmann, F., Goller, S., &amp; Buschek, D. (2022). How to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models.
<a href="#fnref-100" class="footnote-backref">↩</a></li><li id="fn-101">Akyürek, A. F., Paik, S., Kocyigit, M. Y., Akbiyik, S., Runyun, Ş. L., &amp; Wijaya, D. (2022). On Measuring Social Biases in Prompt-Based Multi-Task Learning.
<a href="#fnref-101" class="footnote-backref">↩</a></li><li id="fn-102">Jin, Y., Kadam, V., &amp; Wanvarie, D. (2022). Plot Writing From Pre-Trained Language Models.
<a href="#fnref-102" class="footnote-backref">↩</a></li><li id="fn-103">Nadeem, M., Bethke, A., &amp; Reddy, S. (2021). StereoSet: Measuring stereotypical bias in pretrained language models. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 5356–5371. https://doi.org/10.18653/v1/2021.acl-long.416
<a href="#fnref-103" class="footnote-backref">↩</a></li><li id="fn-104">Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y., Madotto, A., &amp; Fung, P. (2022). Survey of Hallucination in Natural Language Generation. ACM Computing Surveys. https://doi.org/10.1145/3571730
<a href="#fnref-104" class="footnote-backref">↩</a></li><li id="fn-105">Liu, J., Shen, D., Zhang, Y., Dolan, B., Carin, L., &amp; Chen, W. (2022). What Makes Good In-Context Examples for GPT-3? Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures. https://doi.org/10.18653/v1/2022.deelio-1.10
<a href="#fnref-105" class="footnote-backref">↩</a></li><li id="fn-106">Yuan, A., Coenen, A., Reif, E., &amp; Ippolito, D. (2022). Wordcraft: Story Writing With Large Language Models. 27th International Conference on Intelligent User Interfaces, 841–852.
<a href="#fnref-106" class="footnote-backref">↩</a></li><li id="fn-107">Fadnavis, S., Dhurandhar, A., Norel, R., Reinen, J. M., Agurto, C., Secchettin, E., Schweiger, V., Perini, G., &amp; Cecchi, G. (2022). PainPoints: A Framework for Language-based Detection of Chronic Pain and Expert-Collaborative Text-Summarization. arXiv Preprint arXiv:2209.09814.
<a href="#fnref-107" class="footnote-backref">↩</a></li><li id="fn-108">Wang, Y., Kordi, Y., Mishra, S., Liu, A., Smith, N. A., Khashabi, D., &amp; Hajishirzi, H. (2022). Self-Instruct: Aligning Language Model with Self Generated Instructions.
<a href="#fnref-108" class="footnote-backref">↩</a></li><li id="fn-109">Guo, J., Li, J., Li, D., Tiong, A. M. H., Li, B., Tao, D., &amp; Hoi, S. C. H. (2022). From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models.
<a href="#fnref-109" class="footnote-backref">↩</a></li><li id="fn-110">Schick, T., &amp; Schütze, H. (2020). Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference.
<a href="#fnref-110" class="footnote-backref">↩</a></li><li id="fn-111">Kirchenbauer, J., Geiping, J., Wen, Y., Katz, J., Miers, I., &amp; Goldstein, T. (2023). A Watermark for Large Language Models. https://arxiv.org/abs/2301.10226
<a href="#fnref-111" class="footnote-backref">↩</a></li></ol></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/trigaten/promptgineering/tree/v1.2.3/docs/bibliography.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文档分页导航"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/vocabulary"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">📙 Vocabulary Reference</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/products"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">📦 Prompted Products</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#prompt-engineering-strategies" class="table-of-contents__link toc-highlight">Prompt Engineering Strategies</a><ul><li><a href="#ask-me-anything-promptingarora2022ama-" class="table-of-contents__link toc-highlight">Ask-Me-Anything Prompting(@arora2022ama) 🔵</a></li></ul></li><li><a href="#reliability" class="table-of-contents__link toc-highlight">Reliability</a></li><li><a href="#automated-prompt-engineering" class="table-of-contents__link toc-highlight">Automated Prompt Engineering</a></li><li><a href="#models" class="table-of-contents__link toc-highlight">Models</a><ul><li><a href="#language-models" class="table-of-contents__link toc-highlight">Language Models</a></li><li><a href="#image-models" class="table-of-contents__link toc-highlight">Image Models</a></li></ul></li><li><a href="#soft-prompting" class="table-of-contents__link toc-highlight">Soft Prompting</a></li><li><a href="#datasets" class="table-of-contents__link toc-highlight">Datasets</a></li><li><a href="#image-prompt-engineering" class="table-of-contents__link toc-highlight">Image Prompt Engineering</a></li><li><a href="#prompt-engineering-ides" class="table-of-contents__link toc-highlight">Prompt Engineering IDEs</a></li><li><a href="#tooling" class="table-of-contents__link toc-highlight">Tooling</a></li><li><a href="#applied-prompt-engineering" class="table-of-contents__link toc-highlight">Applied Prompt Engineering</a></li><li><a href="#user-interface-design" class="table-of-contents__link toc-highlight">User Interface Design</a></li><li><a href="#prompt-injection" class="table-of-contents__link toc-highlight">Prompt Injection</a></li><li><a href="#jailbreaking" class="table-of-contents__link toc-highlight">Jailbreaking</a></li><li><a href="#surveys" class="table-of-contents__link toc-highlight">Surveys</a></li><li><a href="#dataset-generation" class="table-of-contents__link toc-highlight">Dataset Generation</a></li><li><a href="#applications" class="table-of-contents__link toc-highlight">Applications</a></li><li><a href="#miscl" class="table-of-contents__link toc-highlight">Miscl</a><ul><li><a href="#ask-me-anything-promptingarora2022ama" class="table-of-contents__link toc-highlight">Ask-Me-Anything Prompting(@arora2022ama)</a></li><li><a href="#a-watermark-for-large-language-modelskirchenbauer2023watermarking" class="table-of-contents__link toc-highlight">A Watermark for Large Language Models(@kirchenbauer2023watermarking)</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Learn Prompting.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.09e77fb9.js"></script>
<script src="/assets/js/main.581c32c8.js"></script>
</body>
</html>